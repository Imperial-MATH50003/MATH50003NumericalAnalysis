**Numerical Analysis MATH50003 (2023–24) Revision Sheet**


**Problem 1(a)** State which real number is represented by an IEEE 16-bit floating point number (with $σ = 15, Q = 5$, and $S = 10$) with bits
$$
{\tt 1\ 01000\ 0000000001}
$$

**SOLUTION**
The sign bit is 1 so the answer is negative. The exponent bits correspond to
$$
q = 2^3 = 8
$$
The significand is
$$
(1.0000000001)_2 = 1 + 2^{-10}
$$
So this represents
$$
-2^{8-σ} (1 + 2^{-10}) = - 2^{-7} (1 + 2^{-10})
$$

**END**

**Problem 1(b)**  How are the following real numbers rounded to the nearest $F_{16}$?
$$
1/2, 1/2 + 2^{-12}, 3 + 2^{-9} + 2^{-10}, 3 + 2^{-10} + 2^{-11}.
$$

**SOLUTION**
$1/2$ is already a float. We have
$$
1/2 + 2^{-12} = (0.100000000001)_2 = 2^{-1} (1.00000000001)_2
$$
This is exactly at the midpoint so is rounded down so the last bit is 0, that is, it is rounded
to $1/2$.  Next we have
$$
3 + 2^{-9}  + 2^{-10} = (11.0000000011)_2 = 2(1.10000000011)_2.
$$
This time we are are exactly at the midpoint but we round up so the last bit is 0 giving us
$$
2(1.100000001)_2 = 3 + 2^{-8}.
$$
Finally,
$$
3 + 2^{-10} + 2^{-11} = 2(1.100000000011)_2
$$
This we round up since we are above the midpoint giving us
$$
2(1.1000000001)_2 = 3 + 2^{-9}.
$$
**END**

**Problem 2(a)** Consider a Lower triangular matrix with floating point entries:
$$
L = \begin{bmatrix}
ℓ_{11} \\
 ℓ_{21} & ℓ_{22} \\
 ⋮ & ⋱ & ⋱ \\
 ℓ_{n1} & ⋯ & ℓ_{n,n-1} & ℓ_{nn}
 \end{bmatrix} ∈ F_{σ,Q,S}^{n × n}
$$
and a vector $𝐱 \in F_{σ,Q,S}^{n}$, where $F_{σ,Q,S}$ is a set of floating-point numbers.
Denoting matrix-vector multiplication implemented using floating point arithmetic as
$$
𝐛 := {\tt lowermul}(L,𝐱)
$$
express the entries $b_k := {\bf e}_k^⊤ 𝐛$  in terms of $ℓ_{kj}$ and $x_k := {\bf e}_k^⊤ 𝐱$, 
using rounded floating-point operations $⊕$ and $⊗$.

**SOLUTION**
$$
b_k = ⨁_{j=1}^k (ℓ_{kj} ⊗ x_j)
$$

**END**

**Problem 2(b)** Assuming all operations involve normal floating numbers, show that your approximation has the form
$$
L 𝐱 = {\tt lowermul}(L, 𝐱) + 𝛜
$$
where, for $ϵ_{\rm m}$ denoting machine epsilon and $E_{n,ϵ}:= {n ϵ \over 1-nϵ}$ and assuming $n ϵ_{\rm m} < 2$,
$$
\| 𝛜 \|_1 ≤   2E_{n,ϵ_{\rm m}/2}   \|L\|_1 \| 𝐱 \|_1.
$$
Here we use  the matrix norm $\| A \|_1 := \max_j ∑_{k=1}^n |a_{kj}|$
and the vector norm $\| 𝐱 \|_1 := ∑_{k=1}^n |x_k|$. You may use the fact that
$$
x_1 ⊕ ⋯ ⊕ x_n = x_1 +  ⋯ + x_n + σ_n
$$
where
$$
|σ_n| ≤ \| 𝐱 \|_1 E_{n-1,ϵ_{\rm m}/2}.
$$


**SOLUTION**

We have
$$
b_k = (⨁_{j=1}^k ℓ_{kj} ⊗ x_j) =
(⨁_{j=1}^k ℓ_{kj} x_j (1 + δ_j)) =
(∑_{j=1}^k ℓ_{kj} x_j (1 + δ_j)) + σ_k
$$
where
$$
|σ_k| ≤ M_k E_{k-1,ϵ_{\rm m}/2}
$$
for
$$
M_k := ∑_{j=1}^k  |ℓ_{kj}| |x_j| |1 + δ_j| ≤ 2 ∑_{j=1}^k  |ℓ_{kj}| |x_j|.
$$
Thus
$$
b_k = 𝐞_k^⊤ L 𝐱 + \underbrace{∑_{j=1}^{k} ℓ_{kj} x_j δ_j + σ_k}_{ε_k}.
$$
where
$$
|ε_k| ≤ ∑_{j=1}^{k} |ℓ_{kj}| |x_j| (|δ_j| + 2 E_{k-1,ϵ_{\rm m}/2})
≤  2E_{k,ϵ_{\rm m}/2} ∑_{j=1}^{k} |ℓ_{kj}| |x_j|
$$
where we use
$$
\begin{align*}
 (|δ_j| + 2 E_{k-1,ϵ_{\rm m}/2}) &≤ {ϵ_{\rm m} \over 2} + 2 {(k-1) {ϵ_{\rm m} / 2} \over 1-(k-1){ϵ_{\rm m}/ 2}} \cr
 &= {ϵ_{\rm m}/2 - (k-1)ϵ_{\rm m}^2/4 +  2(k-1) {ϵ_{\rm m} / 2} \over 1-(k-1){ϵ_{\rm m}/ 2}} \cr
 &≤ {2k {ϵ_{\rm m} / 2} \over 1-k{ϵ_{\rm m}/ 2}} = 2E_{k,ϵ_{\rm m}/ 2}.
\end{align*}
$$
We then have using $E_{k,ϵ_{\rm m}/ 2} ≤ E_{n,ϵ_{\rm m}/ 2}$,
$$
\meeq{
\| 𝛜 \|_1 = ∑_{k=1}^n |ε_k| ≤ 2E_{n,ϵ_{\rm m}/2} ∑_{k=1}^n ∑_{j=1}^k |ℓ_{kj}| |x_j | \ccr
=  2E_{n,ϵ_{\rm m}/2} ∑_{j=1}^n  |x_j | ∑_{k=1}^{n-j+1} |ℓ_{kj}| ≤ 2E_{n,ϵ_{\rm m}/2}  ∑_{j=1}^n  |x_j | \|L\|_1 \ccr
= 2E_{n,ϵ_{\rm m}/2} \|L\|_1 \| 𝐱\|_1.
}
$$

**END**



**Problem 3** What is the dual extension of square-roots? I.e. what should $\sqrt{a + b ϵ}$ equal assuming $a > 0$?

**SOLUTION**
$$
\sqrt{a + b ϵ} = \sqrt{a} + {b \over 2 \sqrt{a}}  ϵ
$$
**END**





**Problem 4** Use the Cholesky factorisation to determine
whether the following matrix is symmetric positive definite:
$$
\begin{bmatrix} 2 & 2 & 1  \\
2 & 3 & 2\\
1 & 2 & 2
\end{bmatrix}
$$

**SOLUTION**

Here $α_1 = 2$ and $𝐯 = [2,1]$ giving us
$$
\begin{align*}
A_2 &= \begin{bmatrix}
3&2\\
2&2
\end{bmatrix}-{1 \over 2} \begin{bmatrix} 2 \\ 1 \end{bmatrix}\begin{bmatrix} 2 & 1 \end{bmatrix}\\
&=
\begin{bmatrix}
1&1\\
1&3/2
\end{bmatrix}
\end{align*}
$$
Thus $α_2 = 1$ and $𝐯 = [1]$ giving us
$$
\begin{align*}
A_3 &= [3/2 - 1] = [1/2]
\end{align*}
$$
As $α_3 = 1/2 > 0$ we know a Cholesky decomposition exists hence $A$ is SPD. In particular we have computed
$A = LL^⊤$ where
$$
L = \begin{bmatrix}
\sqrt{2} \\
\sqrt{2} & 1 \\
1/\sqrt{2} & 1 & 1/\sqrt{2}
\end{bmatrix}
$$

**END**

**Problem 5** Use reflections to determine the entries of an orthogonal matrix $Q$ such that
$$
Q \begin{bmatrix} 2 \\ 1 \\ 2 \end{bmatrix} =  \begin{bmatrix} -3 \\ 0 \\ 0 \end{bmatrix}.
$$

**SOLUTION**

$$
\begin{align*}
𝐱 &:= [2,1,2], \| 𝐱 \| = 3\\
𝐲 &:= \|𝐱\| 𝐞_1 + 𝐱 = [5,1,2], \| 𝐲 \| = \sqrt{30} \\
𝐰 &:= 𝐲 / \| 𝐲 \| = [5,1,2] /  \sqrt{30} \\
Q &:= I - 2𝐰 𝐰^⊤ = I - {1 \over 15} \begin{bmatrix}5 \\ 1 \\ 2 \end{bmatrix} [5\ 1\ 2] = I - {1 \over 15} \begin{bmatrix} 25 & 5 & 10 \\5 & 1 & 2 \\ 10 & 2 & 4 \end{bmatrix} \\
&= {1 \over 15} \begin{bmatrix} -10 & -5 & -10 \\ -5 & 14 & -2 \\ -10 & -2 & 11 \end{bmatrix}
\end{align*}
$$

**END**





**Problem 6** For the function $f(θ) = \sin 3 θ$, state explicit formulae for its Fourier coefficients
$$
\hat f_k := {1 \over 2π} \int_0^{2π} f(θ) {\rm e}^{-{\rm i} k θ} {\rm d}θ
$$
and  their discrete approximation:
$$
\hat f_k^n := {1 \over n} \sum_{j=0}^{n-1} f(θ_j) {\rm e}^{-{\rm i} k θ_j}.
$$
for _all_ integers $k$, $n = 1,2,…$, where $θ_j = 2π j/n$.

**SOLUTION**

We have
$$
f(θ) = \sin 3 θ = { \exp(3 i θ) \over 2 i} -  { \exp(-3 i θ) \over 2 i}
$$
hence $\hat f_3 = 1/(2i)$, $\hat f_{-3} = -1/(2i)$ and $\hat f_k = 0$ otherwise. Thus we have:
$$
\begin{align*}
\hat f_k^1 &= \sum_{k=-∞}^∞ \hat f_k = \hat f_{-3} + \hat f_3 = 0, \\
\hat f_{2k}^2 &= 0, \hat f_{2k+1}^2 = \hat f_{-3} + \hat f_3 = 0, \\
\hat f_{3k}^3 &= \hat f_{-3} + \hat f_3 = 0, \hat f_{3k+1}^3 = \hat f_{3k-1}^3 = 0, \\
\hat f_{4k}^4 &= \hat f_{4k+2}^4 = 0, \hat f_{4k+1}^4 = \hat f_{-3} = -1/(2i), \hat f_{4k+3}^4 = \hat f_{3} = 1/(2i) \\
\hat f_{5k}^5 &= \hat f_{5k+1}^5 = \hat f_{5k+4}^5,  \hat f_{5k+2}^5 = \hat f_{-3} = -1/(2i),  \hat f_{5k+3}^5 = \hat f_{3} = 1/(2i), \\
\hat f_{6k}^6 &= \hat f_{6k+1}^6 = \hat f_{6k+2}^6 = \hat f_{6k+4}^6 = \hat f_{6k+5}^6,  \hat f_{6k+3}^5 = \hat f_{-3} + \hat f_{3} = 0
\end{align*}
$$
For $n > 6$ we have
$$
\hat f_{-3+nk}^n =  \hat f_{-3} = -{1 \over 2i},\hat f_{3+nk}^n =  \hat f_{3} = {1 \over 2i}
$$
and all other $\hat f_k^n = 0$.

**END**






**Problem 7** Consider orthogonal polynomials
$$
H_n(x) = 2^n x^n + O (x^{n-1})
$$
as $x → ∞$ and $n = 0, 1, 2, …$,  orthogonal with respect to the inner product
$$
\langle f, g \rangle = \int_{-∞}^∞ f(x) g(x) w(x) {\rm d}x, \qquad w(x) = \exp(-x^2)
$$
Construct $H_0(x)$, $H_1(x)$, $H_2(x)$ and hence show that $H_3(x) = 8x^3-12x$. You may use without proof the formulae
$$
\int_{-∞}^∞ w(x) {\rm d}x = \sqrt{π}, \int_{-∞}^∞ x^2 w(x) {\rm d}x = \sqrt{π}/2,
\int_{-∞}^∞ x^4 w(x) {\rm d}x = 3\sqrt{π}/4.
$$

**SOLUTION**

Because $w(x) = w(-x)$ we know that $a_k$ is zero. We further know that $H_0(x) = 1$ with $\|H_0\|^2 = \sqrt{π}$
 and $H_1(x) = 2x$ with
$$
\| H_1 \|^2 = 4 ∫_{-∞}^∞ x^2 w(x) {\rm d}x = 2 \sqrt{π}.
$$

We have
$$
 x H_1(x) = c_0 H_0(x) + H_2(x)/2
$$
where
$$
c_0 = {⟨ x H_1(x), H_0(x) ⟩ \over \|H_0\|^2 } = {\sqrt{π}  \over \sqrt{π}} = 1
$$
Hence $H_2(x) = 2 x H_1(x) - H_0(x) = 4x^2-2$, which satisfies
$$
\|H_2\|^2 = 16 ∫_{-∞}^∞ x^4 w(x) {\rm d } x - 16∫_{-∞}^∞ x^2 w(x) {\rm d}x + 4 ∫_{-∞}^∞  w(x) {\rm d}x =
(12 -8 + 4) \sqrt{π} = 8 \sqrt{π}.
$$
We further have
$$
⟨ x H_2(x), H_1(x) ⟩ =  ∫_{-∞}^∞ (8x^4 - 4 x^2) w(x) {\rm d} x = (6 -2) \sqrt{π} = 4 \sqrt{π}
$$
Finally we have
$$
 x H_2(x) = c_1 H_1(x) + H_3(x)/2
$$
where
$$
c_1 = {⟨ x H_2(x), H_1(x) ⟩ \over \|H_1\|^2 } = { 4 \sqrt{π}  \over 2 \sqrt{π}} = 2
$$
Hence
$$
H_3(x) = 2x H_2(x) - 4 H_1(x) = 8x^3 - 12x.
$$



**END**



**Problem 8(a)** Derive the 3-point Gauss quadrature formula
$$
\int_{-∞}^∞ f(x) \exp(-x^2) {\rm d}x ≈ w_1 f(x_1) + w_2 f(x_2) + w_3 f(x_3)
$$
with analytic expressions for $x_j$ and $w_j$.

**SOLUTION**

We know $x_k$ are the roots of $H_3(x) = 8x^3 - 12x$ hence we have $x_2 = 0$ and the other roots satisfy
$$
2x^2 - 3 = 0,
$$
i.e., $x_1 = -\sqrt{3/2}$ and $x_2 = \sqrt{3/2}$. To deduce the weights the easiest approach is to use Lagrange
interpolation. An alternative is to orthonormalise. Note the Jacobi matrix satisfies
$$
x [H_0 | H_1 | H_2 | H_3 | …] = [H_0 | H_1 | H_2 | H_3 | …] \underbrace{\begin{bmatrix} 0 & 1  \\
                                                                    1/2 & 0 & 2 \\
                                                                       & 1/2 & 0 &  ⋱\\
                                                                          && 1/2 & ⋱ \\
                                                                                &&& ⋱ \end{bmatrix}}_X
$$
To find $q_k = d_k H_k$, orthonormalised versions of Hermite, we need to choose $d_k$ to symmetrise $X$,
that is for $D = {\rm diag}(d_0,d_1,…)$ we have
$$
x [q_0 | q_1 | …] = x [H_0 | H_1 | …] D = [H_0 | H_1 | …] X D = [q_0 | q_1 | …] D^{-1} X D
$$
where
$$
D^{-1} X D = \begin{bmatrix}                                                 0 & d_1/d_0  \\
                                                                    d_0/(2d_1) & 0 & 2d_2/d_1 \\
                                                                    & d_1/(2d_2) & 0 &  ⋱\\
                                                                        && d_2/(2d_3) & ⋱ \\
                                                                     &&& ⋱ \end{bmatrix}
$$
Note $d_0 = 1/\sqrt{∫_{-∞}^∞ \exp(-x^2) {\rm d} x } = 1/π^{1/4}$
then we have
$$
\begin{align*}
d_0^2 &= 2 d_1^2 ⇒ d_1 = 1/(\sqrt{2} π^{1/4}) \\
d_1^2 &= 4 d_2^2 ⇒ d_2 = 1/(2\sqrt{2} π^{1/4})
\end{align*}
$$
We thus have
$$
\meeq{
w_1 = {1 \over q_0(-\sqrt{3/2})^2 + q_1(-\sqrt{3/2})^2 + q_2(-\sqrt{3/2})^2} =
{1 \over d_0^2 + 4d_1^2 (3/2) + d_2^2 (6 - 2)^2} = {\sqrt{π} \over 6} \ccr
w_2 = {1 \over q_0(0)^2 + q_1(0)^2 + q_2(0)^2} =
{1 \over d_0^2 + d_2^2 (2)^2} = {2\sqrt{π} \over  3} \ccr
w_3 = w_1 = {\sqrt{π} \over 6}.
}
$$


**END**



**Problem 8(b)** Compute the 2-point and 3-point Gaussian quadrature rules associated with $w(x) = 1$ on $[-1,1]$.

**SOLUTION**

For the weights $w(x) = 1$, the orthogonal polynomials of degree $≤ 3$ are the Legendre polynomials,
$$
\begin{align*}
	P_0(x) = 1, \\
	P_1(x) = x, \\
	P_2(x) = \frac{1}{2}(3x^2  - 1), \\
	P_3(x) = \frac{1}{2}(5x^3 - 3x)
\end{align*}
$$
which can be found from, e.g, the Rodriguez formula or by direct construction.
We can normalise each to get $q_j(x) = P_j(x)/\|P_j\|$, with $\|P_j\|^2 = \int_{-1}^1 P_j^2 dx$. This gives,
$$
\begin{align*}
	q_0(x) &= \frac{1}{\sqrt{2}}, \\
	q_1(x) &= \sqrt{\frac{3}{2}}x, \\
	q_2(x) &= \sqrt{\frac{5}{8}}(3x^2  - 1), \\
	q_3(x) &= \sqrt{\frac{7}{8}}(5x^3 - 3x).
\end{align*}
$$
For the first part we use the roots of $P_2(x)$ which are $𝐱 = \left\{± \frac{1}{\sqrt{3}}\right\}$. The weights are,
$$
w_j = \frac{1}{α_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2} = \frac{1}{\frac{1}{2}+\frac{3}{2}x_j^2},
$$
where $α_j$ is the same as in III.6 Lemma 2,
so that,
$$
w_1 = w_2 = 1,
$$
and the Gaussian Quadrature rule is,
$$
Σ_2^w[f] = f\left(-\frac{1}{\sqrt{3}}\right) + f\left(\frac{1}{\sqrt{3}}\right)
$$
For the second part, we use the roots of $P_3(x)$ which are $𝐱 = \left\{0, ± \sqrt{\frac{3}{5}} \right\}$. The weights are then,
$$
w_j = \frac{1}{α_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2 + q_2(x_j)^2} = \frac{1}{\frac{9}{8} -\frac{9}{4}x_j^2 + \frac{45}{8}x_j^4 }
$$
Giving us,
$$
\begin{align*}
	w_1 = w_3 = \frac{1}{\frac{9}{8} - \frac{9}{4}\frac{3}{5} + \frac{45}{8}\frac{9}{25}} &= \frac{5}{9} \\
	w_2 &= \frac{8}{9}
\end{align*}
$$
Then the Gaussian Quadrature rule is,
$$
Σ_3^w[f] = \frac{1}{9} \left[5f\left(-\sqrt\frac{3}{5}\right) +8f(0) + 5f\left(\sqrt\frac{3}{5}\right) \right]
$$

**END**



**Problem 9** Solve Problem 4(b) from PS8 using **Lemma 12 (discrete orthogonality)** with
$w(x) = 1/\sqrt{1-x^2}$ on $[-1,1]$. That is, use the connection of $T_n(x)$ with $\cos n θ$ to
show that the Discrete Cosine Transform
$$
C_n := \begin{bmatrix}
\sqrt{1/n} \\
 & \sqrt{2/n} \\
 && ⋱ \\
 &&& \sqrt{2/n}
 \end{bmatrix}
\begin{bmatrix}
    1 & ⋯ & 1\\
    \cos θ_1 & ⋯ & \cos θ_n \\
    ⋮ & ⋱ & ⋮ \\
    \cos (n-1)θ_1 & ⋯ & \cos (n-1)θ_n
\end{bmatrix}
$$
for $θ_j = π(j-1/2)/n$ is an orthogonal matrix.

**SOLUTION**


Our goal is to show that $C_n C_n^⊤ = I$. By  Lemma 12 (Discrete Orthogonality) and PS10 Q5, we have,
$$
\begin{align*}
	Σ_{n}^w[q_lq_m] = \frac{π}{n}\sum_{j=1}^n q_l(x_j)q_m(x_j) = δ_{lm}.
\end{align*}
$$
where for the weight $w(x) = \frac{1}{\sqrt{1-x^2}}$ we have the orthonormal polynomials $q_0(x_j) = \frac{1}{\sqrt{π}}$, $q_k(x_j) = \sqrt{\frac{2}{π}}\cos(k θ_j).$
Thus we have:
$$
\meeq{
𝐞_1^⊤ C_n C_n^⊤ 𝐞_1 = \sqrt{1/n} [1,1,…,1] \begin{bmatrix}1 \\ ⋮ \\ 1 \end{bmatrix}  \sqrt{1/n} = {1 \over n} ∑_{j=1}^n 1 = 1 \ccr
𝐞_k^⊤ C_n C_n^⊤ 𝐞_1 = 𝐞_1^⊤ C_n C_n^⊤ 𝐞_k = \sqrt{1/n} [1,1,…,1] \begin{bmatrix}\cos (k-1) θ_1 \\ ⋮ \\ \cos (k-1) θ_n \end{bmatrix}  \sqrt{2/n} \ccr
=
 {1 \over n} π ∑_{ℓ=1}^n q_k(x_ℓ)q_0(x_ℓ) = 0 \ccr
 𝐞_k^⊤ C_n C_n^⊤ 𝐞_j = \sqrt{2/n} [\cos (k-1) θ_1, … , \cos (k-1) θ_n] \begin{bmatrix}\cos (j-1) θ_1 \\ ⋮ \\ \cos (j-1) θ_n \end{bmatrix}  \sqrt{2/n} \ccr 
 =
 {π \over n} ∑_{ℓ=1}^n q_k(x_ℓ)q_j(x_ℓ) = δ_{kj}.
}
$$

**END**
