{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MATH50003 (2024–25)\n",
    "# Lab 7: IV.1 Polynomial Interpolation and Regression and IV.2 Differential Equations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We  explore polynomial interpolation and regression, and see that when\n",
    "interpolating at an evenly spaced grid one can encounter issues with convergence.\n",
    "This is overcome via regression, but we are left with the question of how to\n",
    "solve the underlying least squares problems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also explore the reduction of differential equations to\n",
    "banded linear systems via divided differences. When we get lower bidiagonal systems these can be solved\n",
    "using forward substitution, whereas we will discuss the tridiagonal case later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Learning Outcomes**\n",
    "\n",
    "Mathematical knowledge:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Vandermonde matrices and least squares.\n",
    "2. Constructing interpolatory quadrature rules.\n",
    "2. Issues with interpolation at evenly spaced points with functions with small radii of convergence.\n",
    "3. Reduction of differential equations to bidiagonal or tridiagonal linear systems.\n",
    "4. Two-point boundary value problems and their convergence rates."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Coding knowledge:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. The error function `erfi` as provided by SpecialFunctions.jl."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first load  packages we need including a couple new ones:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# LinearAlgebra contains routines for doing linear algebra\n",
    "using LinearAlgebra, Plots, Test"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Remark** One should normally not need to implement methods for solving differential equations\n",
    "oneself as there are packages available, including the high-performance\n",
    " Julia package  [DifferentialEquations.jl](https://github.com/SciML/DifferentialEquations.jl). Moreover Forward and Backward\n",
    "Euler are only the first baby steps to a wide range of time-steppers, with Runge–Kutta being\n",
    "one of the most successful.\n",
    "For example, in practice we can solve\n",
    "a simple differential equation like a pendulum $u'' = -\\sin u$ can be solved\n",
    "as follows (writing at a system $u' = v, v' = -\\sin u$):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using DifferentialEquations, LinearAlgebra, Plots\n",
    "\n",
    "u = solve(ODEProblem((u,_,x) -> [u[2], -sin(u[1])], [1,0], (0,10)))\n",
    "plot(u)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, even in these automated packages one has a choice of different methods with\n",
    "different behaviour, so it is important to understand on a mathematical level what is happening under the hood."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IV.1 Polynomial Interpolation and Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now explore the practical usage of polynomial interpolation and regression.\n",
    "In particular we will see that polynomial interpolation may fail as the number\n",
    "of points becomes large."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.1.1 Polynomial Interpolation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A quick-and-dirty way to to do interpolation is to invert the Vandermonde matrix.\n",
    "That is, for\n",
    "$$\n",
    "p(x) = ∑_{k = 0}^{n-1} c_k x^k\n",
    "$$\n",
    "and $x_1, …, x_n ∈ ℝ$, we choose $c_k$ so that $p(x_j) = f(x_j)$ for\n",
    "$j = 1, …, n$. We do so by creating the square Vandermonde matrix\n",
    "$$\n",
    "V := \\begin{bmatrix} 1 & x_1 & ⋯ & x_1^{n-1} \\\\\n",
    "                    ⋮ & ⋮ & ⋱ & ⋮ \\\\\n",
    "                    1 & x_n & ⋯ & x_n^{n-1}\n",
    "                    \\end{bmatrix}.\n",
    "$$\n",
    "If the function samples are\n",
    "$$\n",
    " 𝐟 = \\begin{bmatrix} f(x_1) \\\\ ⋮ \\\\ f(x_n) \\end{bmatrix}\n",
    "$$\n",
    "then the coefficients of the interpolatory polynomial\n",
    "$$\n",
    "      𝐜 = \\begin{bmatrix}\n",
    "          c_0 \\\\ ⋮ \\\\ c_{n-1} \\end{bmatrix}\n",
    "$$\n",
    "must satisfy $V 𝐜 = 𝐟$.  Thus inverting the Vandermonde matrix tells us the coefficients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we see an example of this using `n` evenly spaced points:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f = x -> cos(10x)\n",
    "n = 5\n",
    "𝐱 = range(0, 1; length=n) # evenly spaced points (BAD for interpolation)\n",
    "V =  [𝐱[j]^k for j = 1:n, k = 0:n-1] # Vandermonde matrix, also can be written as x .^ (0:n)'\n",
    "𝐟 = f.(𝐱) # evaluate f at x[k], equivalent to [f(x[k]) for k = 1:n]\n",
    "𝐜 = V \\ 𝐟 # invert the Vandermonde matrix and determine the coefficients\n",
    "p = x -> dot(𝐜, x .^ (0:n-1)) # take a dot product with monomials x .^ 0:n-1 == [x^j for j=0:n-1]\n",
    "@test p.(𝐱) ≈ V * 𝐜 # evaluating the polynomial on x is the same as applying V\n",
    "\n",
    "\n",
    "𝐠 = range(0,1; length=1000) # plotting grid, sample a lot more than interpolation points\n",
    "\n",
    "# To evaluate a polynomial on the plotting grid its faster to create the rectangular Vandermonde matrix associated with that grid:\n",
    "V_g = [𝐠[j]^k for j = 1:length(𝐠), k = 0:n-1]\n",
    "\n",
    "plot(𝐠, f.(𝐠); label=\"function\")\n",
    "plot!(𝐠, V_g*𝐜; label=\"interpolation\")\n",
    "scatter!(𝐱, f.(𝐱); label=\"samples\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whether an interpolation is actually close to a function is a subtle question,\n",
    "involving properties of the function, distribution of the sample points $x_1,…,x_n$,\n",
    "and round-off error.\n",
    "A classic example is:\n",
    "$$\n",
    "  f_M(x) = {1 \\over M x^2 + 1}\n",
    "$$\n",
    "where the choice of $M$ can dictate whether interpolation at evenly spaced points converges."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 1** Interpolate $1/(4x^2+1)$ and $1/(25x^2 + 1)$ at an evenly spaced grid of $n$\n",
    "points, plotting the solution at a grid of $1000$ points. For $n = 50$ does your interpolation match\n",
    "the true function?  Does increasing $n$ to 400 improve the accuracy? How about using `BigFloat`?\n",
    "Hint: make sure to make your `range` be `BigFloat` valued, e.g., `range(big(-1), big(1); length=n)`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: interpolate 1/(10x^2 + 1) and 1/(25x^2 + 1) at $n$ evenly spaced points, plotting both solutions evaluated at\n",
    "# the plotting grid with 1000 points, for $n = 50$ and $400$."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.1.2 Interpolatory quadrature rules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "An interpolatory quadrature rule consists of interpolating samples of a function and integrating\n",
    "the polynomial exactly. In the notes we constructed such rules by integrating the Lagrange basis,\n",
    "however, we can also compute the interpolatory polynomial by inverting the Vandermonde matrix.\n",
    "Here we explore this construction."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 2(a)** Complete the following function that computes an interpolatory quadrature\n",
    "$$\n",
    "\\int_0^1 f(x) {\\rm d}x ≈ \\int_0^1 p(x) {\\rm d}x\n",
    "$$\n",
    "where $p(x)$ interpolates the data $𝐟 = [f_1,…,f_n]$ (given as a vector) at the given points $𝐱 = [x_1,…,x_n]$ (given as a vector).\n",
    "Hint: it is much easier to solve a linear system involving the Vandermonde matrix than to use a Lagrange basis."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function interpolatoryquadrature(f::AbstractVector, x::AbstractVector)\n",
    "    if length(f) ≠ length(x)\n",
    "        error(\"lengths must match\")\n",
    "    end\n",
    "    # TODO: Compute the coefficients of the interpolatory polynomial and integrate it exactly.\n",
    "\n",
    "end\n",
    "\n",
    "x = range(0, 1, 10)\n",
    "@test interpolatoryquadrature(exp.(x), x) ≈ exp(1)-1"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 2(b)**  Plot the error for the number of evenly spaced points $n = 2, 3, …, 100$ for approximating the integrals\n",
    "$$\n",
    "∫_0^1 \\exp x {\\rm d}x  = ℯ - 1, ∫_0^1 {{\\rm d} x \\over 25x^2 + 1} = {\\rm arctan}(5)/5.\n",
    "$$\n",
    "How does the convergence behaviour compare with the Trapezium rule? Does the approximation appear to be stable?\n",
    "Does using `BigFloat` improve the results? (Hint: `range(0,big(1),n)` will make a sequence of `BigFloat` points.)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "nanabs(x) = x == 0 ? NaN : abs(x)\n",
    "# TODO: plot the errors for 2,…,100 evenly spaced points for approximating the integral of exp(x) and 1/(25x^2+1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 2(c)** Repeat the previous problem with the points $x_j = (\\cos θ_j + 1)/2$ where $θ_j$ are $n$ evenly spaced points\n",
    "between $0$ and $π$. How do the results compare with evenly spaced points?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: plot the errors for 2,…,100 points that are cosines of evenly spaced points, shifted/scaled to be between 0 and 1."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 3** Typically it's more convenient to compute the quadrature weights $w_j$ so that\n",
    "$$\n",
    "\\int_0^1 f(x) {\\rm d}x ≈ \\int_0^1 p(x) {\\rm d}x = ∑_{j=1}^n w_j f(x_j).\n",
    "$$\n",
    "Compute these weights by solving a linear system involving the transpose of the Vandermonde  matrix."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function interpolatoryweights(x::AbstractVector)\n",
    "    # TODO: Construct the interpolatory quadrature weights as a vector by solving a linear system involving V'\n",
    "\n",
    "end\n",
    "\n",
    "# We test on the example from the notes:\n",
    "@test interpolatoryweights([0,1/4,1]) ≈ [-1/6, 8/9, 5/18]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.1.3 Polynomial regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To overcome issues with interpolation we will instead use regression: use more points than\n",
    "the degree of the polynomial. As an example, suppose we want to fit noisy data by a quadratic\n",
    "$$\n",
    "p(x) = c₀ + c₁ x + c₂ x^2.\n",
    "$$\n",
    "That is, we want to choose $c₀,c₁,c₂$ at data samples $x_1, …, x_m$ so that the following is true:\n",
    "$$\n",
    "c₀ + c₁ x_j + c₂ x_j^2 ≈ f_j\n",
    "$$\n",
    "where $f_j$ are given by data. We can reinterpret this as a least squares problem: minimise the norm\n",
    "$$\n",
    "\\left\\| \\begin{bmatrix} 1 & x_1 & x_1^2 \\\\ ⋮ & ⋮ & ⋮ \\\\ 1 & x_m & x_m^2 \\end{bmatrix}\n",
    "\\begin{bmatrix} p₀ \\\\ p₁ \\\\ p₂ \\end{bmatrix} - \\begin{bmatrix} f_1 \\\\ ⋮ \\\\ f_m \\end{bmatrix} \\right \\|\n",
    "$$\n",
    "When a matrix is rectangular `\\` solves a least squares problem for us:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "m,n = 100,3\n",
    "\n",
    "𝐱 = range(0,1; length=m) # 100 points\n",
    "𝐟 = 2 .+ 𝐱 .+ 2𝐱.^2 .+ 0.1 .* randn.() # Noisy quadratic samples, built with broadcast notation.\n",
    "\n",
    "V = 𝐱 .^ (0:2)'  # 100 x 3 Vandermonde matrix, equivalent to [ones(m) x x.^2]\n",
    "\n",
    "𝐜 = V \\ 𝐟 # coefficients are, very roughly, [2,1,2]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can visualise the fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "𝐠 =range(0, 1; length=1000)\n",
    "\n",
    "p = x -> 𝐜[1] + 𝐜[2]x + 𝐜[3]x^2\n",
    "\n",
    "scatter(𝐱, 𝐟; label=\"samples\", legend=:bottomright)\n",
    "plot!(𝐠, p.(𝐠); label=\"quadratic\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 4** Repeat  Problem 1 but now using _least squares_: instead of interpolating,\n",
    "use least squares on a large grid: choose the coefficients of a degree $(n-1)$ polynomial so that\n",
    "$$\n",
    "    \\left\\| \\begin{bmatrix} p(x_1) \\\\ ⋮ \\\\ p(x_m) \\end{bmatrix} - \\begin{bmatrix} f(x_1) \\\\ ⋮ \\\\ f(x_m) \\end{bmatrix} \\right \\|.\n",
    "$$\n",
    "is minimised, where $n = 50$ and $m = 500$.\n",
    "Does this improve the accuracy near the endpoints? Do you think convergence for a least squares approximation\n",
    "is dictated by the radius of convergence of the corresponding Taylor series?\n",
    "Hint: use the rectangular Vandermonde matrix to setup the Least squares system. The solution will look extremely similar to Problem 1."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: approximate 1/(10x^2 + 1) and 1/(25x^2 + 1) using a least squares system."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IV.2 Differential Equations via Finite Differences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now turn to an important application of banded linear algebra:\n",
    "approximating solutions to linear differential equations. We will focus on first and second order\n",
    "but the techniques generalise beyond this, to vector problems, nonlinear differential equations, and partial differential equations.\n",
    "In particular we explore _finite difference_ approximations which use divided differences to replace derivatives.\n",
    "These are the most basic type of numerical method and many powerful alternatives\n",
    "exist, including Finite Element Methods and spectral methods."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.2.1 Indefinite integration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use the right-sided divided difference to approximate derivatives.  Let's do an example of integrating $\\cos x$ by discretising the ODE\n",
    "$$\n",
    " u(0) = c, \\qquad u'(x) = f(x)\n",
    "$$\n",
    "and see if our method matches\n",
    "the true answer of $\\sin x$. Recall from the notes that this equation can be approximated by $u_k$ solving the bidiagonal linear system\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    -1/h & 1/h \\\\\n",
    "    & ⋱ & ⋱ \\\\\n",
    "    && -1/h & 1/h \\end{bmatrix} \\begin{bmatrix}u_0\\\\u_1\\\\⋮\\\\u_n\\end{bmatrix} = \\begin{bmatrix}c\\\\ f(x_0)\\\\ ⋮ \\\\ f(x_{n-1})\\end{bmatrix}.\n",
    "$$\n",
    "We can construct the bidiagonal matrix as follows:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n = 10\n",
    "x = range(0, 1; length=n+1) # makes an n+1 point evenly spaced grid\n",
    "h = step(x) # equivalent to 1/n\n",
    "L = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use this bidiagonal matrix along with `\\` to solve the\n",
    "system via forward substitution:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "c = 0 # u(0) = 0\n",
    "f = x -> cos(x)\n",
    "\n",
    "𝐟 = f.(x[1:end-1]) # evaluate f at all but the last point\n",
    "𝐛 = [c; 𝐟]\n",
    "𝐮 = L \\ 𝐛 # integrate using forward-differences\n",
    "\n",
    "plot(x, sin.(x); label=\"sin(x)\", legend=:bottomright)\n",
    "scatter!(x, 𝐮; label=\"forward\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " We can estimate how fast it converges by measuring\n",
    "the ∞-norm error (using $\\| 𝐱 \\|_∞ := \\max |x_k|$ which\n",
    "is implemented as `norm(x,Inf)`):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Error from indefinite integration with c and f\n",
    "function forward_err(u, c, f, n)\n",
    "    x = range(0, 1; length = n+1)\n",
    "    h = step(x) # equivalent to 1/n\n",
    "    L = Bidiagonal([1; fill(1/h, n)], fill(-1/h, n), :L)\n",
    "    𝐮 = L\\ [c; f.(x[1:end-1])]\n",
    "    errs = 𝐮 - u.(x) # compare numerics with \"true\" result\n",
    "    norm(errs, Inf) # measure ∞-norm error\n",
    "end\n",
    "\n",
    "\n",
    "ns = 10 .^ (1:8) # solve up to n = 10 million\n",
    "scatter(ns, forward_err.(sin, 0, f, ns); xscale=:log10, yscale=:log10, label=\"forward\")\n",
    "plot!(ns, ns .^ (-1); label=\"1/n\", linestyle=:dash)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that the method converges linearly (like $O(n^{-1})$)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 5(a)** In the problem sheet we derived Backward Euler using the left-sided divided difference\n",
    "$$\n",
    "  u'(x) ≈ {u(x) - u(x-h) \\over h}\n",
    "$$\n",
    "Implement Backward Euler to approximate\n",
    "indefinite-integration. How does the error compare to forward\n",
    "for $f(x) = \\cos x$ on the interval $[0,1]$?\n",
    "Use the method to approximate the indefinite intergral of\n",
    "$$\n",
    "\\exp(\\exp x \\cos x + \\sin x)\n",
    "$$\n",
    "to 3 digits."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Implement Backward Euler by constructing a lower bidiagonal linear system."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 5(b)** Implement indefinite-integration\n",
    "where we impose the equation on the midpoints $x̃_1,…,x̃_n$ defined as\n",
    "$$\n",
    "x̃_j = {x_{j+1} + x_j \\over 2} = a + (j-1/2)h\n",
    "$$\n",
    "using the central difference formula\n",
    "$$\n",
    "u'(x̃_j) ≈ {u(x_j) - u(x_{j-1}) \\over h}\n",
    "$$\n",
    "By plotting the errors show that this method converges at\n",
    "a faster rate than Forward or Backward Euler for $f(x) = \\cos x$ on the interval $[0,1]$."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Discretise at midpoints rather than our grid. The solution is still approximated on the original grid."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.2.2 Forward Euler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now adapt the approach for more general ODEs of the form\n",
    "$$\n",
    "  u'(x) + ω(x)u(x) = f(x), u(0) = c.\n",
    "$$\n",
    "We now have the system:\n",
    "$$\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "1 \\\\\n",
    "ω(x_0)-1/h & 1/h \\\\\n",
    "& ⋱ & ⋱ \\\\\n",
    "&& ω(x_{n-1})-1/h & 1/h \\end{bmatrix}}_L \\underbrace{\\begin{bmatrix}u_0 \\\\ u_1 \\\\ ⋮ \\\\ u_n\\end{bmatrix} }_{𝐮} = \\begin{bmatrix} c \\\\ f(x_0) \\\\ ⋮ \\\\ f(x_{n-1}) \\end{bmatrix}\n",
    "$$\n",
    "Consider the simple example:\n",
    " $$\n",
    " u(0) = 1, u' + x u = {\\rm e}^x\n",
    " $$\n",
    " which has an exact solution in terms of a special error function\n",
    " (which I determined using Mathematica)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SpecialFunctions\n",
    "c = 1\n",
    "ω = x -> x\n",
    "n = 200\n",
    "x = range(0, 1; length=n+1)\n",
    "# exact solution, found in Mathematica\n",
    "u = x -> -(1/2)*exp(-(1+x^2)/2)*(-2sqrt(ℯ) + sqrt(2π)erfi(1/sqrt(2)) - sqrt(2π)erfi((1 + x)/sqrt(2)))\n",
    "\n",
    "h = step(x)\n",
    "L = Bidiagonal([1; fill(1/h, n)], ω.(x[1:end-1]) .- 1/h, :L)\n",
    "\n",
    "𝐛 = [c; exp.(x[1:end-1])]\n",
    "𝐮 = L \\ 𝐛\n",
    "\n",
    "plot(x, u.(x); label=\"u(x)\", legend=:bottomright)\n",
    "scatter!(x, 𝐮; label=\"forward\")\n",
    "\n",
    "# We see that it is converging to the true result."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem  6** Implement backward Euler for solving:\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) &= 1, u'(t) - \\cos(t) u(t) = t\n",
    "\\end{align*}\n",
    "$$\n",
    "on the interval $[0,1]$. Approximate $u(1)$ to three digits accuracy."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Implement backward Euler for the case with a variable coefficient."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IV.2.3 Poisson equation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now consider the Poisson equation with Dirichlet\n",
    "boundary conditions. In particular consider a case where\n",
    "we know the true answer: if $u(x) = \\cos x^2$ then it solves the ODE:\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) = \\underbrace{1}_c \\\\\n",
    "u''(x) = \\underbrace{-4x^2 \\cos(x^2) - 2\\sin(x^2)}_{f(x)} \\\\\n",
    "u(1) = \\underbrace{\\cos 1}_d\n",
    "\\end{align*}\n",
    "$$\n",
    "We approximate it by the solution to the tridiagonal system:\n",
    "$$\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    1/h^2 & -2/h^2 & 1/h \\\\\n",
    "    & ⋱ & ⋱ & ⋱ \\\\\n",
    "   && 1/h^2 & -2/h^2 & 1/h \\\\\n",
    "   &&&& 1 \\end{bmatrix}}_A \\underbrace{\\begin{bmatrix}u_0\\\\u_1\\\\⋮\\\\u_n\\end{bmatrix} }_{𝐮} = \\underbrace{\\begin{bmatrix}c\\\\ f(x_0)\\\\ f(x_1)\\\\ ⋮ \\\\ f(x_{n-1})\\\\ d\\end{bmatrix} }_{𝐛}\n",
    "$$\n",
    "We first construct the matrix $A$ using `Tridiagonal`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n = 20\n",
    "x = range(0, 1; length = n + 1)\n",
    "h = step(x)\n",
    "A = Tridiagonal([fill(1/h^2, n-1); 0],\n",
    "                [1; fill(-2/h^2, n-1); 1],\n",
    "                [0; fill(1/h^2, n-1)])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus we get an approximation to our (known) solution:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "u = x -> cos(x^2)\n",
    "f = x -> -4x^2*cos(x^2) - 2sin(x^2)\n",
    "𝐛 =  [1; f.(x[2:end-1]); cos(1)]\n",
    "𝐮 = A \\ 𝐛\n",
    "plot(x, u.(x); label=\"u(x)\", legend=:bottomright)\n",
    "scatter!(x, 𝐮; label=\"finite differences\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 7(a)** Estimate the rate of convergence in the ∞-norm using the previous example with an increasing number of grid points."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Plot the ∞-norm error and estimate the convergence rate."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 7(b)** Construct a finite-difference approximation to the\n",
    "forced Helmholtz equation\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) &= 0 \\\\\n",
    "u(1) &= 0 \\\\\n",
    "u'' + k^2 u &= {\\rm e}^x\n",
    "\\end{align*}\n",
    "$$\n",
    "and find an $n$ such  the error is less than $10^{-4}$ when compared\n",
    "with the true solution for $k=10$:\n",
    "$$\n",
    "u(x) = (-\\cos(k x) + {\\rm e}^x \\cos(k x)^2 + \\cot(k) \\sin(k x) - {\\rm e} \\cos(k) \\cot(k) \\sin(k x) - {\\rm e} \\sin(k) \\sin(k x) + {\\rm e}^x \\sin(k x)^2)/(1 + k^2)\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Generalise the second-order finite differences to allow for a $k^2 u$ term."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 8(a)** Consider the Helmholtz equations\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) &= 0 \\\\\n",
    "u(1) &= 0 \\\\\n",
    "u'' + k^2 u &= {\\rm e}^x\n",
    "\\end{align*}\n",
    "$$\n",
    "discretised with finite-differences to result in a tridiagonal system.\n",
    "Use the `lu` function without pivoting to\n",
    "compute the LU factorization of the tridiagonal matrix. What sparsity structure\n",
    "do you observe in `L` and `U`? Does this structure depend on $n$ or $k$?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Apply lu to the discretisation for Helmholtz derived in the last lab and investigate its structure."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 8(b)** Repeat Problem 8(a) but with a PLU factorisation.\n",
    "Are $L$ and $U$ still banded?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Check sparsity of PLU factorisation"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
