# Dual Numbers

In this section we introduce a mathematically beautiful  alternative to divided differences for computing
derivatives: _dual numbers_. These are a commutative ring that _exactly_ compute derivatives,
which when implemented on a computer gives very high-accuracy approximations to derivatives. They
underpin forward-mode [automatic differentation](https://en.wikipedia.org/wiki/Automatic_differentiation).
Automatic differentiation  is a basic tool in Machine Learning for computing gradients necessary
for training neural networks.



**Definition (Dual numbers)** Dual numbers $ğ”»$ are a commutative ring (over $â„$)
generated by $1$ and $Ïµ$ such that $Ïµ^2 = 0$, that is,
$$
ğ”» := \{a + bÏµ \quad :\quad
 a,b \in â„, \quad Ïµ^2 =0 \}.
$$
âˆ

This is very much analoguous to complex numbers, which are a field generated by $1$ and $\I$ such that
$\I^2 = -1$, that is,
$$
â„‚ := \{a + b\I \quad :\quad
 a,b \in â„, \quad \I^2 =-1 \}.
$$
Compare multiplication of each number type which falls out of the rules of the generators:
$$
\meeq{
(a + b \I) (c + d \I) = ac + (bc + ad) \I + bd \I^2 = ac -bd + (bc + ad) \I, \ccr
(a + b Ïµ) (c + d Ïµ) = ac + (bc + ad) Ïµ + bd Ïµ^2 = ac  + (bc + ad) Ïµ.
}
$$
And just as we view $â„ âŠ‚ â„‚$ by equating $a âˆˆ â„$ with $a + 0\I âˆˆ â„‚$,
we can view $â„ âŠ‚ ğ”»$ by equating $a âˆˆ â„$ with $a + 0{\rm Ïµ} âˆˆ ğ”»$.

Conceptually, dual numbers can be thought of as introducing an infinitesimally small $Ïµ$, where
$Ïµ^2$ is so small it is treated as zero. This is the intuitive reason they allow for differentiation
of functions. But we do not need to appeal to this calculus-like interpretation,
instead, their construction and relationship to differentiation can be accomplished using purely
algebraic reasoning.

## Differentiating polynomials

Polynomials evaluated on dual numbers are well-defined as
they depend only on the operations $+$ and $*$. From the formula for multiplication of dual numbers
we deduce that evaluating a polynomial at a dual number $a + b Ïµ$ tells us the derivative of the polynomial at $a$:

**Theorem (polynomials on dual numbers)** Suppose $p$ is a polynomial. Then
$$
p(a + b Ïµ) = p(a) + b p'(a) Ïµ
$$

**Proof**

First consider $p(x) = x^n$ for $n â‰¥ 0$. 
The cases $n = 0$ and $n = 1$ are immediate. For $n > 1$ we have by induction:
$$
(a + b Ïµ)^n = (a + b Ïµ) (a + b Ïµ)^{n-1} = (a + b Ïµ) (a^{n-1} + (n-1) b a^{n-2} Ïµ) = a^n + b n a^{n-1} Ïµ.
$$
For a more general polynomial
$$
p(x) = âˆ‘_{k=0}^n c_k x^k
$$
the result follows from linearity:
$$
p(a + b Îµ) = âˆ‘_{k=0}^n c_k (a+bÏµ)^k = c_0 + âˆ‘_{k=1}^n c_k (a^k +k b a^{k-1}Ïµ)
= âˆ‘_{k=0}^n c_k a^k + b âˆ‘_{k=1}^n c_k k a^{k-1}Ïµ = p(a) + b p'(a) Ïµ.
$$

âˆ

**Example (differentiating polynomial)** Consider computing $p'(2)$ where
$$
p(x) = (x-1)(x-2) + x^2.
$$
We can use dual numbers to differentiate, avoiding expanding in monomials
or applying rules of differentiating:
$$
p(2+Ïµ) = (1+Ïµ)Ïµ + (2+Ïµ)^2 = Ïµ + 4 + 4Ïµ = 4 + \underbrace{5}_{p'(2)}Ïµ.
$$
âˆ


## Differentiating other functions


We can extend real-valued differentiable functions to dual numbers in a similar manner.
First, consider a standard function with a Taylor series (e.g. ${\rm cos}$, ${\rm sin}$, ${\rm exp}$, etc.)
$$
f(x) = âˆ‘_{k=0}^âˆ f_k x^k
$$
so that $a$ is inside the radius of convergence. This leads naturally to a definition on dual numbers:
$$
\meeq{
f(a + b Ïµ) = âˆ‘_{k=0}^âˆ f_k (a + b Ïµ)^k = f_0 + âˆ‘_{k=1}^âˆ f_k (a^k + k a^{k-1} b Ïµ) = âˆ‘_{k=0}^âˆ f_k a^k +  âˆ‘_{k=1}^âˆ f_k k a^{k-1} b Ïµ  \ccr
  = f(a) + b f'(a) Ïµ.
}
$$
More generally, given a differentiable function (which may not have a Taylor series) we can extend it to dual numbers:

**Definition (dual extension)** Suppose a real-valued function $f : Î© â†’ â„$ is differentiable in $Î© âŠ‚ â„$. 
We can construct the _dual extension_ $fÌ² : Î© + Ïµâ„ â†’ ğ”»$ by defining
$$
fÌ²(a + b Ïµ) := f(a) + b f'(a) Ïµ.
$$
By viewing $â„ âŠ‚ ğ”»$, it is natural to reuse the notation $f$ for the dual extension,
hence when there's no chance of confusion we will identify $f(a + b Ïµ) â‰¡ fÌ²(a+b Ïµ)$.
âˆ

Thus, for basic functions we have natural extensions:
$$
\begin{align*}
\exp(a + b Ïµ) &:= \exp(a) + b \exp(a) Ïµ & (a,b âˆˆ â„) \\
\sin(a + b Ïµ) &:= \sin(a) + b \cos(a) Ïµ & (a,b âˆˆ â„) \\
\cos(a + b Ïµ) &:= \cos(a) - b \sin(a) Ïµ & (a,b âˆˆ â„) \\
\log(a + b Ïµ) &:= \log(a) + {b \over a} Ïµ & (a âˆˆ (0,âˆ), b âˆˆ â„) \\
\sqrt{a+b Ïµ} &:= \sqrt{a} + {b \over 2 \sqrt{a}} Ïµ & (a âˆˆ (0,âˆ), b âˆˆ â„) \\
|a + b Ïµ| &:= |a| + b\, {\rm sign} a\, Ïµ & (a âˆˆ â„ \backslash \{0\} , b âˆˆ â„)
\end{align*}
$$
provided the function is differentiable at $a$. Note the last example does not have
a convergent Taylor series (at $0$) but we can still extend it where it is differentiable.

Going further, we can add, multiply, and compose such dual-extensions. And the beauty is these automatically
satisfy the right properties to be dual-extensions themselves, thus allowing for differentiation of  complicated functions
built from basic differentiable building blocks.

The following lemma shows that addition and multiplication in some sense â€œcommute" with the dual-extension,
hence we can recover the product rule from dual number multiplication:

**Lemma (addition/multiplication)** Suppose $f,g : Î© â†’ â„$ are differentiable for $Î© âŠ‚ â„$ and $c âˆˆ â„$. Then
for $a âˆˆ Î©$ and $b âˆˆ â„$ we have
$$
\meeq{
\underline{f+g}(a+bÏµ) = fÌ²(a+bÏµ) + gÌ²(a+bÏµ) \ccr 
\underline{c f}(a+bÏµ) = c fÌ²(a+b Ïµ) \ccr
\underline{f g}(a+bÏµ) = fÌ²(a+b Ïµ) gÌ²(a+b Ïµ)
}
$$

**Proof**
The first two are immediate due to linearity:
$$
\meeq{
\underline{(f+g)}(a+bÏµ) = (f+g)(a) + b(f + g)'(a) Ïµ \ccr
 = (f(a)+bf'(a)Ïµ) + (g(a)+bg'(a)Ïµ) = fÌ²(a+bÏµ) + gÌ²(a+bÏµ), \ccr
\underline{cf}(a+bÏµ) = (cf)(a) + b(cf)'(a) Ïµ = c(f(a)+bf'(a)Ïµ) = cfÌ²(a+bÏµ).
}
$$
The last property essentially captures the product rule of differentiation:
$$
\meeq{
\underline{f g}(a+bÏµ) = f(a)g(a) + b (f(a)g'(a)+f'(a) g'(a))Ïµ  \ccr
= (f(a)+bf'(a)Ïµ)(g(a)+b g'(a)Ïµ) = fÌ²(a+b Ïµ) gÌ²(a+b Ïµ).
}
$$
âˆ

Furthermore composition recovers the chain rule:

**Lemma (composition)** 
Suppose $f : Î“ â†’ â„$ and $g : Î© â†’ Î“$ are differentiable in $Î©,Î“ âŠ‚ â„$. Then
$$
\underline{(f âˆ˜ g)}(a+b Ïµ) = fÌ²(gÌ²(a+bÏµ))
$$

**Proof**
Again it falls out of the properties of dual numbers:
$$
\underline{(f âˆ˜ g)}(a+b Ïµ) = f(g(a)) + bg'(a) f'(g(a)) Ïµ = fÌ²(g(a)+bg'(a)Ïµ) = fÌ²(gÌ²(a+bÏµ))
$$
âˆ

A simple corollary is that any function defined in terms of addition, multiplication, composition, etc.
of basic functions with dual-extensions will be differentiable via dual numbers. In this following example we see a practical realisation
of this, where we differentiate a function by just evaluating it on dual numbers, implicitly, using the dual-extension
for the basic build blocks:

**Example (differentiating non-polynomial)**

Consider differentiating $f(x) =  \exp(x^2 + \cos x)$ at the point $a = 1$, where 
we automatically use the dual-extension of $\exp$ and $\cos$. We can differentiate $f$
by simply evaluating on the duals:
$$
f(1 + Ïµ) = \exp(1 + 2Ïµ + \cos 1 - \sin 1 Ïµ) =  \exp(1 + \cos 1) + \exp(1 + \cos 1) (2 - \sin 1) Ïµ.
$$
Therefore we deduce that
$$
f'(1) = \exp(1 + \cos 1) (2 - \sin 1).
$$


âˆ

