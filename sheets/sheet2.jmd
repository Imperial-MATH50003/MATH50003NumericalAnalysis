**Numerical Analysis MATH50003 (2024‚Äì25) Problem Sheet 2**


This problem sheet explores using dual numbers as a means to calculating derivatives
by hand, to help build a better understanding of how a computer uses them for computing derivatives
in an algorithmic fashion.
It's important to not resort to traditional differentiation rules (i.e. chain or product rule)
when solving these problems. 

The first problem considers some very basic polynomials where we use only the ring properties of
dual numbers:

-----

**Problem 1** Using dual number arithmetic, compute the following polynomials evaluated at the
dual number $2+œµ$ and use this to deduce their derivative at $2$:
$$
2x^2 + 3x + 4, (x+1)(x+2)(x+3), (2x+1)x^3.
$$



----

The next problems consider cases where the multiplication and addition are not sufficient,
or in the first example, prohibitively expensive (I'm not expecting you to multiply a dual number 100 
times!). Nevertheless, we can define their values applied on a dual number using the dual extension.
Here you can use the traditional derivative rules in order to answer this question.



-----


**Problem 2** What should the following functions applied to dual numbers return for $x = a+b œµ$:
$$
f(x) = x^{100} + 1, g(x) = 1/x, h(x) = \tan x.
$$






**Problem 3(a)** What is the correct definition of division on dual numbers, i.e., for what choice of $s$ and $t$
does the following hold:
$$
(a + b œµ )/(c + d œµ ) = s + t œµ.
$$




**Problem 3(b)** A _field_ is a commutative ring such that $0 ‚â† 1$ and all nonzero elements have a multiplicative inverse, i.e.,
there exists $a^{-1}$ such that $a a^{-1} = 1$. Can we use the previous part to define $a^{-1} := 1/a$ to make $ùîª$ a field? Why or why not?


 

-----

The next problem shows that once we have defined functions like $\exp$, $\cos$, $\sin$, or division on dual numbers
we can actually compose these definitions to differentiate more complicated functions. 
That is, you may use the dual extension for each of the building blocks here, but _do not_ use it on the more complicated
function, rather, compute it algorithmically via dual numbers.

----


**Problem 4** Use dual numbers to compute the derivative of the following functions at $x = 0.1$:
$$
\exp(\exp x \cos x + \sin x), \prod_{k=1}^3 \left({x \over k}-1\right),\hbox{ and } f^{\rm s}_2(x) = {1 + {x - 1 \over 2 + {x-1 \over 2}}}
$$




----

Dual numbers can be extended to higher dimensions via a 2D analogue of dual numbers $a + b œµ_x + c œµ_y$ defined by the relationship
 $œµ_x œµ_y = œµ_x^2 =  œµ_y^2 = 0$.   This allows for computation of gradients. 
 In Problem 5 we build up these properties to show that we can compute gradients of higher dimensional
 polynomials using 2D dual numbers.

 ----

**Problem 5(a)** 
Derive the formula for writing the product of two 2D dual numbers $(a + a_x œµ_x + a_y œµ_y) (b + b_x œµ_x + b_y œµ_y)$
where $a,a_x,a_y,b,b_x,b_y \in \mathbb R$ as a 2D dual number.



**Problem 5(b)** Show  for all 2D polynomials
$$
p(x,y) = \sum_{k=0}^n \sum_{j=0}^m c_{kj} x^k y^j
$$
that
$$
\begin{align*}
p(x + a œµ_x, y + b œµ_y) &= p(x,y) + a  {‚àÇ p \over ‚àÇ x} œµ_x  +  b  {‚àÇ p \over ‚àÇ y}   œµ_y.
\end{align*}
$$



**Problem 5(c)** Use 2D dual numbers to compute the gradient of $p(x,y) = (1 + x + 3xy)(1+y)$ at $x=1$ and $y=2$.



----

We now turn to Newton's method. In the lectures/notes we saw that we could derive an error bound
when the derivative of a function did not vanish at the root. Here we see that we can still derive an error
bound even when the derivative vanishes at the root, though the rate of convergence is much weaker.

-----

**Problem 6** Suppose $f$ is twice-differentiable in a neighbourhood of $B$ of $r$ such that $f(r) = f'(r) = 0$, where $f''$ does not vanish
in $B$. Show 
that the error of the $k$-th Newton iteration $Œµ_k := r - x_k$ satisfies
$$
|Œµ_{k+1}| ‚â§ MÃÉ |Œµ_k|
$$
where 
$$
MÃÉ ={1 \over 2} \sup_{y \in B} |f''(y)|  \sup_{y \in B} {1 \over |f''(y)|}.
$$




----