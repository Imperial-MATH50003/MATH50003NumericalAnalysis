**Numerical Analysis MATH50003 (2024â€“25) Revision Sheet**


**Problem 1(a)** State which real number is represented by an IEEE 16-bit floating point number (with $Ïƒ = 15, Q = 5$, and $S = 10$) with bits
$$
{\tt 1\ 01000\ 0000000001}
$$

**SOLUTION**
The sign bit is 1 so the answer is negative. The exponent bits correspond to
$$
q = 2^3 = 8
$$
The significand is
$$
(1.0000000001)_2 = 1 + 2^{-10}
$$
So this represents
$$
-2^{8-Ïƒ} (1 + 2^{-10}) = - 2^{-7} (1 + 2^{-10})
$$

**END**

**Problem 1(b)**  How are the following real numbers rounded to the nearest $F_{16}$?
$$
1/2, 1/2 + 2^{-12}, 3 + 2^{-9} + 2^{-10}, 3 + 2^{-10} + 2^{-11}.
$$

**SOLUTION**
$1/2$ is already a float. We have
$$
1/2 + 2^{-12} = (0.100000000001)_2 = 2^{-1} (1.00000000001)_2
$$
This is exactly at the midpoint so is rounded down so the last bit is 0, that is, it is rounded
to $1/2$.  Next we have
$$
3 + 2^{-9}  + 2^{-10} = (11.0000000011)_2 = 2(1.10000000011)_2.
$$
This time we are are exactly at the midpoint but we round up so the last bit is 0 giving us
$$
2(1.100000001)_2 = 3 + 2^{-8}.
$$
Finally,
$$
3 + 2^{-10} + 2^{-11} = 2(1.100000000011)_2
$$
This we round up since we are above the midpoint giving us
$$
2(1.1000000001)_2 = 3 + 2^{-9}.
$$
**END**

**Problem 2(a)** Consider a Lower triangular matrix with floating point entries:
$$
L = \begin{bmatrix}
â„“_{11} \\
 â„“_{21} & â„“_{22} \\
 â‹® & â‹± & â‹± \\
 â„“_{n1} & â‹¯ & â„“_{n,n-1} & â„“_{nn}
 \end{bmatrix} âˆˆ F_{Ïƒ,Q,S}^{n Ã— n}
$$
and a vector $ğ± \in F_{Ïƒ,Q,S}^{n}$, where $F_{Ïƒ,Q,S}$ is a set of floating-point numbers.
Denoting matrix-vector multiplication implemented using floating point arithmetic as
$$
ğ› := {\tt lowermul}(L,ğ±)
$$
express the entries $b_k := {\bf e}_k^âŠ¤ ğ›$  in terms of $â„“_{kj}$ and $x_k := {\bf e}_k^âŠ¤ ğ±$, 
using rounded floating-point operations $âŠ•$ and $âŠ—$.

**SOLUTION**
$$
b_k = â¨_{j=1}^k (â„“_{kj} âŠ— x_j)
$$

**END**

**Problem 2(b)** Assuming all operations involve normal floating numbers, show that your approximation has the form
$$
L ğ± = {\tt lowermul}(L, ğ±) + ğ›œ
$$
where, for $Ïµ_{\rm m}$ denoting machine epsilon and $E_{n,Ïµ}:= {n Ïµ \over 1-nÏµ}$ and assuming $n Ïµ_{\rm m} < 2$,
$$
\| ğ›œ \|_1 â‰¤   2E_{n,Ïµ_{\rm m}/2}   \|L\|_1 \| ğ± \|_1.
$$
Here we use  the matrix norm $\| A \|_1 := \max_j âˆ‘_{k=1}^n |a_{kj}|$
and the vector norm $\| ğ± \|_1 := âˆ‘_{k=1}^n |x_k|$. You may use the fact that
$$
x_1 âŠ• â‹¯ âŠ• x_n = x_1 +  â‹¯ + x_n + Ïƒ_n
$$
where
$$
|Ïƒ_n| â‰¤ \| ğ± \|_1 E_{n-1,Ïµ_{\rm m}/2}.
$$


**SOLUTION**

We have
$$
b_k = (â¨_{j=1}^k â„“_{kj} âŠ— x_j) =
(â¨_{j=1}^k â„“_{kj} x_j (1 + Î´_j)) =
(âˆ‘_{j=1}^k â„“_{kj} x_j (1 + Î´_j)) + Ïƒ_k
$$
where
$$
|Ïƒ_k| â‰¤ M_k E_{k-1,Ïµ_{\rm m}/2}
$$
for
$$
M_k := âˆ‘_{j=1}^k  |â„“_{kj}| |x_j| |1 + Î´_j| â‰¤ 2 âˆ‘_{j=1}^k  |â„“_{kj}| |x_j|.
$$
Thus
$$
b_k = ğ_k^âŠ¤ L ğ± + \underbrace{âˆ‘_{j=1}^{k} â„“_{kj} x_j Î´_j + Ïƒ_k}_{Îµ_k}.
$$
where
$$
|Îµ_k| â‰¤ âˆ‘_{j=1}^{k} |â„“_{kj}| |x_j| (|Î´_j| + 2 E_{k-1,Ïµ_{\rm m}/2})
â‰¤  2E_{k,Ïµ_{\rm m}/2} âˆ‘_{j=1}^{k} |â„“_{kj}| |x_j|
$$
where we use
$$
\begin{align*}
 (|Î´_j| + 2 E_{k-1,Ïµ_{\rm m}/2}) &â‰¤ {Ïµ_{\rm m} \over 2} + 2 {(k-1) {Ïµ_{\rm m} / 2} \over 1-(k-1){Ïµ_{\rm m}/ 2}} \cr
 &= {Ïµ_{\rm m}/2 - (k-1)Ïµ_{\rm m}^2/4 +  2(k-1) {Ïµ_{\rm m} / 2} \over 1-(k-1){Ïµ_{\rm m}/ 2}} \cr
 &â‰¤ {2k {Ïµ_{\rm m} / 2} \over 1-k{Ïµ_{\rm m}/ 2}} = 2E_{k,Ïµ_{\rm m}/ 2}.
\end{align*}
$$
We then have using $E_{k,Ïµ_{\rm m}/ 2} â‰¤ E_{n,Ïµ_{\rm m}/ 2}$,
$$
\meeq{
\| ğ›œ \|_1 = âˆ‘_{k=1}^n |Îµ_k| â‰¤ 2E_{n,Ïµ_{\rm m}/2} âˆ‘_{k=1}^n âˆ‘_{j=1}^k |â„“_{kj}| |x_j | \ccr
=  2E_{n,Ïµ_{\rm m}/2} âˆ‘_{j=1}^n  |x_j | âˆ‘_{k=1}^{n-j+1} |â„“_{kj}| â‰¤ 2E_{n,Ïµ_{\rm m}/2}  âˆ‘_{j=1}^n  |x_j | \|L\|_1 \ccr
= 2E_{n,Ïµ_{\rm m}/2} \|L\|_1 \| ğ±\|_1.
}
$$

**END**



**Problem 3** What is the dual extension of square-roots? I.e. what should $\sqrt{a + b Ïµ}$ equal assuming $a > 0$?

**SOLUTION**
$$
\sqrt{a + b Ïµ} = \sqrt{a} + {b \over 2 \sqrt{a}}  Ïµ
$$
**END**





**Problem 4** Use the Cholesky factorisation to determine
whether the following matrix is symmetric positive definite:
$$
\begin{bmatrix} 2 & 2 & 1  \\
2 & 3 & 2\\
1 & 2 & 2
\end{bmatrix}
$$

**SOLUTION**

Here $Î±_1 = 2$ and $ğ¯ = [2,1]$ giving us
$$
\begin{align*}
A_2 &= \begin{bmatrix}
3&2\\
2&2
\end{bmatrix}-{1 \over 2} \begin{bmatrix} 2 \\ 1 \end{bmatrix}\begin{bmatrix} 2 & 1 \end{bmatrix}\\
&=
\begin{bmatrix}
1&1\\
1&3/2
\end{bmatrix}
\end{align*}
$$
Thus $Î±_2 = 1$ and $ğ¯ = [1]$ giving us
$$
\begin{align*}
A_3 &= [3/2 - 1] = [1/2]
\end{align*}
$$
As $Î±_3 = 1/2 > 0$ we know a Cholesky decomposition exists hence $A$ is SPD. In particular we have computed
$A = LL^âŠ¤$ where
$$
L = \begin{bmatrix}
\sqrt{2} \\
\sqrt{2} & 1 \\
1/\sqrt{2} & 1 & 1/\sqrt{2}
\end{bmatrix}
$$

**END**

**Problem 5** Use reflections to determine the entries of an orthogonal matrix $Q$ such that
$$
Q \begin{bmatrix} 2 \\ 1 \\ 2 \end{bmatrix} =  \begin{bmatrix} -3 \\ 0 \\ 0 \end{bmatrix}.
$$

**SOLUTION**

$$
\begin{align*}
ğ± &:= [2,1,2], \| ğ± \| = 3\\
ğ² &:= \|ğ±\| ğ_1 + ğ± = [5,1,2], \| ğ² \| = \sqrt{30} \\
ğ° &:= ğ² / \| ğ² \| = [5,1,2] /  \sqrt{30} \\
Q &:= I - 2ğ° ğ°^âŠ¤ = I - {1 \over 15} \begin{bmatrix}5 \\ 1 \\ 2 \end{bmatrix} [5\ 1\ 2] = I - {1 \over 15} \begin{bmatrix} 25 & 5 & 10 \\5 & 1 & 2 \\ 10 & 2 & 4 \end{bmatrix} \\
&= {1 \over 15} \begin{bmatrix} -10 & -5 & -10 \\ -5 & 14 & -2 \\ -10 & -2 & 11 \end{bmatrix}
\end{align*}
$$

**END**





**Problem 6** For the function $f(Î¸) = \sin 3 Î¸$, state explicit formulae for its Fourier coefficients
$$
\hat f_k := {1 \over 2Ï€} \int_0^{2Ï€} f(Î¸) {\rm e}^{-{\rm i} k Î¸} {\rm d}Î¸
$$
and  their discrete approximation:
$$
\hat f_k^n := {1 \over n} \sum_{j=0}^{n-1} f(Î¸_j) {\rm e}^{-{\rm i} k Î¸_j}.
$$
for _all_ integers $k$, $n = 1,2,â€¦$, where $Î¸_j = 2Ï€ j/n$.

**SOLUTION**

We have
$$
f(Î¸) = \sin 3 Î¸ = { \exp(3 i Î¸) \over 2 i} -  { \exp(-3 i Î¸) \over 2 i}
$$
hence $\hat f_3 = 1/(2i)$, $\hat f_{-3} = -1/(2i)$ and $\hat f_k = 0$ otherwise. Thus we have:
$$
\begin{align*}
\hat f_k^1 &= \sum_{k=-âˆ}^âˆ \hat f_k = \hat f_{-3} + \hat f_3 = 0, \\
\hat f_{2k}^2 &= 0, \hat f_{2k+1}^2 = \hat f_{-3} + \hat f_3 = 0, \\
\hat f_{3k}^3 &= \hat f_{-3} + \hat f_3 = 0, \hat f_{3k+1}^3 = \hat f_{3k-1}^3 = 0, \\
\hat f_{4k}^4 &= \hat f_{4k+2}^4 = 0, \hat f_{4k+1}^4 = \hat f_{-3} = -1/(2i), \hat f_{4k+3}^4 = \hat f_{3} = 1/(2i) \\
\hat f_{5k}^5 &= \hat f_{5k+1}^5 = \hat f_{5k+4}^5,  \hat f_{5k+2}^5 = \hat f_{-3} = -1/(2i),  \hat f_{5k+3}^5 = \hat f_{3} = 1/(2i), \\
\hat f_{6k}^6 &= \hat f_{6k+1}^6 = \hat f_{6k+2}^6 = \hat f_{6k+4}^6 = \hat f_{6k+5}^6,  \hat f_{6k+3}^5 = \hat f_{-3} + \hat f_{3} = 0
\end{align*}
$$
For $n > 6$ we have
$$
\hat f_{-3+nk}^n =  \hat f_{-3} = -{1 \over 2i},\hat f_{3+nk}^n =  \hat f_{3} = {1 \over 2i}
$$
and all other $\hat f_k^n = 0$.

**END**






**Problem 7** Consider orthogonal polynomials
$$
H_n(x) = 2^n x^n + O (x^{n-1})
$$
as $x â†’ âˆ$ and $n = 0, 1, 2, â€¦$,  orthogonal with respect to the inner product
$$
\langle f, g \rangle = \int_{-âˆ}^âˆ f(x) g(x) w(x) {\rm d}x, \qquad w(x) = \exp(-x^2)
$$
Construct $H_0(x)$, $H_1(x)$, $H_2(x)$ and hence show that $H_3(x) = 8x^3-12x$. You may use without proof the formulae
$$
\int_{-âˆ}^âˆ w(x) {\rm d}x = \sqrt{Ï€}, \int_{-âˆ}^âˆ x^2 w(x) {\rm d}x = \sqrt{Ï€}/2,
\int_{-âˆ}^âˆ x^4 w(x) {\rm d}x = 3\sqrt{Ï€}/4.
$$

**SOLUTION**

Because $w(x) = w(-x)$ we know that $a_k$ is zero. We further know that $H_0(x) = 1$ with $\|H_0\|^2 = \sqrt{Ï€}$
 and $H_1(x) = 2x$ with
$$
\| H_1 \|^2 = 4 âˆ«_{-âˆ}^âˆ x^2 w(x) {\rm d}x = 2 \sqrt{Ï€}.
$$

We have
$$
 x H_1(x) = c_0 H_0(x) + H_2(x)/2
$$
where
$$
c_0 = {âŸ¨ x H_1(x), H_0(x) âŸ© \over \|H_0\|^2 } = {\sqrt{Ï€}  \over \sqrt{Ï€}} = 1
$$
Hence $H_2(x) = 2 x H_1(x) - H_0(x) = 4x^2-2$, which satisfies
$$
\|H_2\|^2 = 16 âˆ«_{-âˆ}^âˆ x^4 w(x) {\rm d } x - 16âˆ«_{-âˆ}^âˆ x^2 w(x) {\rm d}x + 4 âˆ«_{-âˆ}^âˆ  w(x) {\rm d}x =
(12 -8 + 4) \sqrt{Ï€} = 8 \sqrt{Ï€}.
$$
We further have
$$
âŸ¨ x H_2(x), H_1(x) âŸ© =  âˆ«_{-âˆ}^âˆ (8x^4 - 4 x^2) w(x) {\rm d} x = (6 -2) \sqrt{Ï€} = 4 \sqrt{Ï€}
$$
Finally we have
$$
 x H_2(x) = c_1 H_1(x) + H_3(x)/2
$$
where
$$
c_1 = {âŸ¨ x H_2(x), H_1(x) âŸ© \over \|H_1\|^2 } = { 4 \sqrt{Ï€}  \over 2 \sqrt{Ï€}} = 2
$$
Hence
$$
H_3(x) = 2x H_2(x) - 4 H_1(x) = 8x^3 - 12x.
$$



**END**



**Problem 8(a)** Derive the 3-point Gauss quadrature formula
$$
\int_{-âˆ}^âˆ f(x) \exp(-x^2) {\rm d}x â‰ˆ w_1 f(x_1) + w_2 f(x_2) + w_3 f(x_3)
$$
with analytic expressions for $x_j$ and $w_j$.

**SOLUTION**

We know $x_k$ are the roots of $H_3(x) = 8x^3 - 12x$ hence we have $x_2 = 0$ and the other roots satisfy
$$
2x^2 - 3 = 0,
$$
i.e., $x_1 = -\sqrt{3/2}$ and $x_2 = \sqrt{3/2}$. To deduce the weights the easiest approach is to use Lagrange
interpolation. An alternative is to orthonormalise. Note the Jacobi matrix satisfies
$$
x [H_0 | H_1 | H_2 | H_3 | â€¦] = [H_0 | H_1 | H_2 | H_3 | â€¦] \underbrace{\begin{bmatrix} 0 & 1  \\
                                                                    1/2 & 0 & 2 \\
                                                                       & 1/2 & 0 &  â‹±\\
                                                                          && 1/2 & â‹± \\
                                                                                &&& â‹± \end{bmatrix}}_X
$$
To find $q_k = d_k H_k$, orthonormalised versions of Hermite, we need to choose $d_k$ to symmetrise $X$,
that is for $D = {\rm diag}(d_0,d_1,â€¦)$ we have
$$
x [q_0 | q_1 | â€¦] = x [H_0 | H_1 | â€¦] D = [H_0 | H_1 | â€¦] X D = [q_0 | q_1 | â€¦] D^{-1} X D
$$
where
$$
D^{-1} X D = \begin{bmatrix}                                                 0 & d_1/d_0  \\
                                                                    d_0/(2d_1) & 0 & 2d_2/d_1 \\
                                                                    & d_1/(2d_2) & 0 &  â‹±\\
                                                                        && d_2/(2d_3) & â‹± \\
                                                                     &&& â‹± \end{bmatrix}
$$
Note $d_0 = 1/\sqrt{âˆ«_{-âˆ}^âˆ \exp(-x^2) {\rm d} x } = 1/Ï€^{1/4}$
then we have
$$
\begin{align*}
d_0^2 &= 2 d_1^2 â‡’ d_1 = 1/(\sqrt{2} Ï€^{1/4}) \\
d_1^2 &= 4 d_2^2 â‡’ d_2 = 1/(2\sqrt{2} Ï€^{1/4})
\end{align*}
$$
We thus have
$$
\meeq{
w_1 = {1 \over q_0(-\sqrt{3/2})^2 + q_1(-\sqrt{3/2})^2 + q_2(-\sqrt{3/2})^2} =
{1 \over d_0^2 + 4d_1^2 (3/2) + d_2^2 (6 - 2)^2} = {\sqrt{Ï€} \over 6} \ccr
w_2 = {1 \over q_0(0)^2 + q_1(0)^2 + q_2(0)^2} =
{1 \over d_0^2 + d_2^2 (2)^2} = {2\sqrt{Ï€} \over  3} \ccr
w_3 = w_1 = {\sqrt{Ï€} \over 6}.
}
$$


**END**



**Problem 8(b)** Compute the 2-point and 3-point Gaussian quadrature rules associated with $w(x) = 1$ on $[-1,1]$.

**SOLUTION**

For the weights $w(x) = 1$, the orthogonal polynomials of degree $â‰¤ 3$ are the Legendre polynomials,
$$
\begin{align*}
	P_0(x) = 1, \\
	P_1(x) = x, \\
	P_2(x) = \frac{1}{2}(3x^2  - 1), \\
	P_3(x) = \frac{1}{2}(5x^3 - 3x)
\end{align*}
$$
which can be found from, e.g, the Rodriguez formula or by direct construction.
We can normalise each to get $q_j(x) = P_j(x)/\|P_j\|$, with $\|P_j\|^2 = \int_{-1}^1 P_j^2 dx$. This gives,
$$
\begin{align*}
	q_0(x) &= \frac{1}{\sqrt{2}}, \\
	q_1(x) &= \sqrt{\frac{3}{2}}x, \\
	q_2(x) &= \sqrt{\frac{5}{8}}(3x^2  - 1), \\
	q_3(x) &= \sqrt{\frac{7}{8}}(5x^3 - 3x).
\end{align*}
$$
For the first part we use the roots of $P_2(x)$ which are $ğ± = \left\{Â± \frac{1}{\sqrt{3}}\right\}$. The weights are,
$$
w_j = \frac{1}{Î±_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2} = \frac{1}{\frac{1}{2}+\frac{3}{2}x_j^2},
$$
where $Î±_j$ is the same as in III.6 Lemma 2,
so that,
$$
w_1 = w_2 = 1,
$$
and the Gaussian Quadrature rule is,
$$
Î£_2^w[f] = f\left(-\frac{1}{\sqrt{3}}\right) + f\left(\frac{1}{\sqrt{3}}\right)
$$
For the second part, we use the roots of $P_3(x)$ which are $ğ± = \left\{0, Â± \sqrt{\frac{3}{5}} \right\}$. The weights are then,
$$
w_j = \frac{1}{Î±_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2 + q_2(x_j)^2} = \frac{1}{\frac{9}{8} -\frac{9}{4}x_j^2 + \frac{45}{8}x_j^4 }
$$
Giving us,
$$
\begin{align*}
	w_1 = w_3 = \frac{1}{\frac{9}{8} - \frac{9}{4}\frac{3}{5} + \frac{45}{8}\frac{9}{25}} &= \frac{5}{9} \\
	w_2 &= \frac{8}{9}
\end{align*}
$$
Then the Gaussian Quadrature rule is,
$$
Î£_3^w[f] = \frac{1}{9} \left[5f\left(-\sqrt\frac{3}{5}\right) +8f(0) + 5f\left(\sqrt\frac{3}{5}\right) \right]
$$

**END**



**Problem 9** Solve Problem 4(b) from PS8 using **Lemma 13 (discrete orthogonality)** with
$w(x) = 1/\sqrt{1-x^2}$ on $[-1,1]$. That is, use the connection of $T_n(x)$ with $\cos n Î¸$ to
show that the Discrete Cosine Transform
$$
C_n := \begin{bmatrix}
\sqrt{1/n} \\
 & \sqrt{2/n} \\
 && â‹± \\
 &&& \sqrt{2/n}
 \end{bmatrix}
\begin{bmatrix}
    1 & â‹¯ & 1\\
    \cos Î¸_1 & â‹¯ & \cos Î¸_n \\
    â‹® & â‹± & â‹® \\
    \cos (n-1)Î¸_1 & â‹¯ & \cos (n-1)Î¸_n
\end{bmatrix}
$$
for $Î¸_j = Ï€(j-1/2)/n$ is an orthogonal matrix.

**SOLUTION**


Our goal is to show that $C_n C_n^âŠ¤ = I$. By  Lemma 13 (Discrete Orthogonality) and PS10 Q4, we have,
$$
\begin{align*}
	Î£_{n}^w[q_lq_m] = \frac{Ï€}{n}\sum_{j=1}^n q_l(x_j)q_m(x_j) = Î´_{lm}.
\end{align*}
$$
where for the weight $w(x) = \frac{1}{\sqrt{1-x^2}}$ we have the orthonormal polynomials $q_0(x_j) = \frac{1}{\sqrt{Ï€}}$, $q_k(x_j) = \sqrt{\frac{2}{Ï€}}\cos(k Î¸_j).$
Thus we have:
$$
\meeq{
ğ_1^âŠ¤ C_n C_n^âŠ¤ ğ_1 = \sqrt{1/n} [1,1,â€¦,1] \begin{bmatrix}1 \\ â‹® \\ 1 \end{bmatrix}  \sqrt{1/n} = {1 \over n} âˆ‘_{j=1}^n 1 = 1 \ccr
ğ_k^âŠ¤ C_n C_n^âŠ¤ ğ_1 = ğ_1^âŠ¤ C_n C_n^âŠ¤ ğ_k = \sqrt{1/n} [1,1,â€¦,1] \begin{bmatrix}\cos (k-1) Î¸_1 \\ â‹® \\ \cos (k-1) Î¸_n \end{bmatrix}  \sqrt{2/n} \ccr
=
 {1 \over n} Ï€ âˆ‘_{â„“=1}^n q_k(x_â„“)q_0(x_â„“) = 0 \ccr
 ğ_k^âŠ¤ C_n C_n^âŠ¤ ğ_j = \sqrt{2/n} [\cos (k-1) Î¸_1, â€¦ , \cos (k-1) Î¸_n] \begin{bmatrix}\cos (j-1) Î¸_1 \\ â‹® \\ \cos (j-1) Î¸_n \end{bmatrix}  \sqrt{2/n} \ccr 
 =
 {Ï€ \over n} âˆ‘_{â„“=1}^n q_k(x_â„“)q_j(x_â„“) = Î´_{kj}.
}
$$

**END**
