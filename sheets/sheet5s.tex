\documentclass[12pt,a4paper]{article}

\usepackage[a4paper,text={16.5cm,25.2cm},centering]{geometry}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage[usenames,dvipsnames]{xcolor}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1.2ex}




\hypersetup
       {   pdfauthor = {  },
           pdftitle={  },
           colorlinks=TRUE,
           linkcolor=black,
           citecolor=blue,
           urlcolor=blue
       }




\usepackage{upquote}
\usepackage{listings}
\usepackage{xcolor}
\lstset{
    basicstyle=\ttfamily\footnotesize,
    upquote=true,
    breaklines=true,
    breakindent=0pt,
    keepspaces=true,
    showspaces=false,
    columns=fullflexible,
    showtabs=false,
    showstringspaces=false,
    escapeinside={(*@}{@*)},
    extendedchars=true,
}
\newcommand{\HLJLt}[1]{#1}
\newcommand{\HLJLw}[1]{#1}
\newcommand{\HLJLe}[1]{#1}
\newcommand{\HLJLeB}[1]{#1}
\newcommand{\HLJLo}[1]{#1}
\newcommand{\HLJLk}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkc}[1]{\textcolor[RGB]{59,151,46}{\textit{#1}}}
\newcommand{\HLJLkd}[1]{\textcolor[RGB]{214,102,97}{\textit{#1}}}
\newcommand{\HLJLkn}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkp}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkr}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkt}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLn}[1]{#1}
\newcommand{\HLJLna}[1]{#1}
\newcommand{\HLJLnb}[1]{#1}
\newcommand{\HLJLnbp}[1]{#1}
\newcommand{\HLJLnc}[1]{#1}
\newcommand{\HLJLncB}[1]{#1}
\newcommand{\HLJLnd}[1]{\textcolor[RGB]{214,102,97}{#1}}
\newcommand{\HLJLne}[1]{#1}
\newcommand{\HLJLneB}[1]{#1}
\newcommand{\HLJLnf}[1]{\textcolor[RGB]{66,102,213}{#1}}
\newcommand{\HLJLnfm}[1]{\textcolor[RGB]{66,102,213}{#1}}
\newcommand{\HLJLnp}[1]{#1}
\newcommand{\HLJLnl}[1]{#1}
\newcommand{\HLJLnn}[1]{#1}
\newcommand{\HLJLno}[1]{#1}
\newcommand{\HLJLnt}[1]{#1}
\newcommand{\HLJLnv}[1]{#1}
\newcommand{\HLJLnvc}[1]{#1}
\newcommand{\HLJLnvg}[1]{#1}
\newcommand{\HLJLnvi}[1]{#1}
\newcommand{\HLJLnvm}[1]{#1}
\newcommand{\HLJLl}[1]{#1}
\newcommand{\HLJLld}[1]{\textcolor[RGB]{148,91,176}{\textit{#1}}}
\newcommand{\HLJLs}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsa}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsb}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsc}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsd}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsdB}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsdC}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLse}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLsh}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsi}[1]{#1}
\newcommand{\HLJLso}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsr}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLss}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLssB}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLnB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnbB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnfB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnh}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLni}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnil}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnoB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLoB}[1]{\textcolor[RGB]{102,102,102}{\textbf{#1}}}
\newcommand{\HLJLow}[1]{\textcolor[RGB]{102,102,102}{\textbf{#1}}}
\newcommand{\HLJLp}[1]{#1}
\newcommand{\HLJLc}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLch}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcm}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcp}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcpB}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcs}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcsB}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLg}[1]{#1}
\newcommand{\HLJLgd}[1]{#1}
\newcommand{\HLJLge}[1]{#1}
\newcommand{\HLJLgeB}[1]{#1}
\newcommand{\HLJLgh}[1]{#1}
\newcommand{\HLJLgi}[1]{#1}
\newcommand{\HLJLgo}[1]{#1}
\newcommand{\HLJLgp}[1]{#1}
\newcommand{\HLJLgs}[1]{#1}
\newcommand{\HLJLgsB}[1]{#1}
\newcommand{\HLJLgt}[1]{#1}


\def\endash{â€“}
\def\bbD{ {\mathbb D} }
\def\bbZ{ {\mathbb Z} }
\def\bbR{ {\mathbb R} }
\def\bbC{ {\mathbb C} }

\def\x{ {\vc x} }
\def\a{ {\vc a} }
\def\b{ {\vc b} }
\def\e{ {\vc e} }
\def\f{ {\vc f} }
\def\u{ {\vc u} }
\def\v{ {\vc v} }
\def\y{ {\vc y} }
\def\z{ {\vc z} }
\def\w{ {\vc w} }

\def\bt{ {\tilde b} }
\def\ct{ {\tilde c} }
\def\Ut{ {\tilde U} }
\def\Qt{ {\tilde Q} }
\def\Rt{ {\tilde R} }
\def\Xt{ {\tilde X} }
\def\acos{ {\rm acos}\, }

\def\red#1{ {\color{red} #1} }
\def\blue#1{ {\color{blue} #1} }
\def\green#1{ {\color{ForestGreen} #1} }
\def\magenta#1{ {\color{magenta} #1} }

\input{somacros}

\begin{document}



\textbf{Numerical Analysis MATH50003 (2024\ensuremath{\endash}25) Problem Sheet 5}

\textbf{Problem 1} Compute the LU factorisation (if possible) and the PLU factorisation, where the entry of largest magnitude is always permuted to the diagonal, of the following matrices:
\[
\begin{bmatrix}
1 & 2 & 0 \\
3 & 1 & 2 \\
0 & 5 & 1
\end{bmatrix}, \begin{bmatrix}
0 &  5 & 5 & 5 \\
1 & 2 & 0 & 0 \\
3 & 3 & 3 & 0 \\
0 & 0  & 3 & 1
\end{bmatrix}
\]
\textbf{SOLUTION}

\emph{Matrix 1} For the LU factorisation we have:
\[
A = \begin{bmatrix}
1 & 2 & 0 \\
3 & 1 & 2 \\
0 & 5 & 1
\end{bmatrix}= \underbrace{\begin{bmatrix}
1 \\
3 & 1 \\
0 & 0 & 1
\end{bmatrix}}_{L_1}   \begin{bmatrix}
1 & 2 & 0 \\
 & -5 & 2 \\
 & 5 & 1
\end{bmatrix}
\]
We now have
\[
A_2 = \begin{bmatrix}
  -5 & 2 \\
  5 & 1 \end{bmatrix} = 
  \underbrace{\begin{bmatrix}
    1\\
    -1 & 1
\end{bmatrix}}_{L_2}   \begin{bmatrix}
  -5 & 2 \\
   & 3 \end{bmatrix}
\]
We can put it together to find:
\[
A = \underbrace{\begin{bmatrix}
1 \\
3 & 1 \\
0 & -1 & 1
\end{bmatrix}}_{L} \underbrace{\begin{bmatrix}
1 & 2 & 0\\
 & -5 & 2 \\
0 & 0 & 3
\end{bmatrix}}_{U}
\]
For the PLU factorisation we need to permute the largest entry to the diagonal each stage:
\[
\underbrace{\begin{bmatrix} 0 & 1 \\
1 & 0 \\
&& 1 \end{bmatrix}}_{P_1} A = \begin{bmatrix}
3 & 1 & 2 \\
1 & 2 & 0 \\
0 & 5 & 1
\end{bmatrix} = \underbrace{\begin{bmatrix}
1 &  &  \\
1/3 & 1 &  \\
0 & 0 & 1
\end{bmatrix}}_{L_1} \begin{bmatrix}
3 & 1 & 2 \\
1 & 5/3 & -2/3 \\
0 & 5 & 1
\end{bmatrix}
\]
We now permute again since $5 > 5/3$:
\[
\underbrace{\begin{bmatrix} 0 & 1 \\
1 & 0 \end{bmatrix}}_{P_2} A_2 = \begin{bmatrix}5 & 1 \\
5/3 & -2/3 \end{bmatrix} = \underbrace{\begin{bmatrix}1 \\
1/3 & 1 \end{bmatrix}}_{L_2} \begin{bmatrix} 5 & 1 \\ & -1 \end{bmatrix}
\]
We thus have:
\[
P_1 A = L_1 \begin{bmatrix} 1 \\ & P_2^\ensuremath{\top} L_2 \end{bmatrix} \underbrace{\begin{bmatrix}  3 & 1 & 2 \\ 
    & 5 & 1 \\ && -1 \end{bmatrix}}_U = 
    = \begin{bmatrix} 1 \\ & P_2^\ensuremath{\top} \end{bmatrix} 
    \underbrace{\begin{bmatrix} 1 \\ 
    0 & 1 \\
    1/3 & 1/3 & 1 \end{bmatrix}}_L U,
\]
that is,
\[
P = \begin{bmatrix} 1 \\ & P_2 \end{bmatrix} P_1 = \begin{bmatrix}
0 & 1 & 0 \\
0 & 0 & 1 \\
1 & 0 & 0
\end{bmatrix}
\]
\emph{Matrix 2}

This has no LU factorisation since the first entry is 0 so we only deduce the PLU. First permute the largest entry to the diagonal by a simple swap and factor:
\[
\underbrace{\begin{bmatrix}
0 &  & 1 \\
 & 1 \\
 1 & & 0 \\
 &&& 1
\end{bmatrix}}_{P_1} A = \begin{bmatrix} 3 & 3 &3 \\
1 & 2 \\
 & 5  & 5 & 5 \\
 && 3 & 1 
 \end{bmatrix} = 
  \underbrace{\begin{bmatrix} 1 &  & \\
1 & 1 \\
1/3 &   &  1 \\
 &&  & 1 
 \end{bmatrix}}_{L_1}
  \begin{bmatrix} 3 & 3 &3 \\
 & 1 & -1 \\
 & 5  & 1 & 2 \\
 && 3 & 1 
 \end{bmatrix}
\]
We repeat with the subslice:
\[
\underbrace{\begin{bmatrix}
0 & 1 &  \\
1 & 0 \\
  & & 1 \\
\end{bmatrix}}_{P_2}  A_2 =
  \begin{bmatrix} 
  5  & 5 & 5 \\
  1 & -1 \\
 & 3 & 1 
 \end{bmatrix} = 
   \underbrace{\begin{bmatrix} 
  1  &  &  \\
  1/5 & 1 \\
0 &  & 1 
 \end{bmatrix}}_{L_2}   \begin{bmatrix} 
  5  & 5 & 5 \\
   & -2 & -1 \\
 & 3 & 1 
 \end{bmatrix}
\]
Finally, we have
\[
\underbrace{\begin{bmatrix}
0 & 1   \\
1 & 0 
\end{bmatrix}}_{P_3}  A_3 = \begin{bmatrix}3 & 1 \\ -2 & -1 \end{bmatrix}
= \underbrace{\begin{bmatrix}1 &  \\ -2/3 & 1 \end{bmatrix}}_{L_3}
\underbrace{\begin{bmatrix}3 & 1 \\  & -1/3 \end{bmatrix}}_{U_3}
\]
We now need to swap the lower matrices and permutations which we do one step at a time.  We already know $A_3 = P_3^\ensuremath{\top} L_3 U_3$ which tells us that
\meeq{
A_2 = P_2^\ensuremath{\top} L_2 \begin{bmatrix} \ensuremath{\alpha}_2 & \ensuremath{\bm{\w}}_2^\ensuremath{\top} \\ & A_3 \end{bmatrix} = 
P_2^\ensuremath{\top} \begin{bmatrix} 1 \\ & P_3^\ensuremath{\top} \end{bmatrix} \begin{bmatrix}
1 \\
P_3 \ensuremath{\bm{\v}}_2/\ensuremath{\alpha}_2 & L_3 \end{bmatrix}  \begin{bmatrix} \ensuremath{\alpha}_2 & \ensuremath{\bm{\w}}_2^\ensuremath{\top} \\ & U_3 \end{bmatrix} \ccr
= \underbrace{\begin{bmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0
\end{bmatrix}}_{\tilde{P}_2^\ensuremath{\top}} \underbrace{\begin{bmatrix} 1 \\ 
0 & 1 \\
1/5 & -2/3 & 1 \end{bmatrix}}_{\tilde{L}_2} \underbrace{\begin{bmatrix} 
  5  & 5 & 5 \\
   & 3 & 1 \\
 &  & -1/3 
 \end{bmatrix}}_{\tilde{U}_2}
}
Finally,
\meeq{
A = P_1^\ensuremath{\top} L_1 \begin{bmatrix} \ensuremath{\alpha}_1 & \ensuremath{\bm{\w}}_1^\ensuremath{\top} \\ & A_2 \end{bmatrix} = 
P_1^\ensuremath{\top} \begin{bmatrix} 1 \\ & \tilde{P}_2^\ensuremath{\top} \end{bmatrix} \begin{bmatrix}
1 \\
\tilde{P}_2 \ensuremath{\bm{\v}}_1/\ensuremath{\alpha}_1 & \tilde{L}_2 \end{bmatrix}  \begin{bmatrix} \ensuremath{\alpha}_1 & \ensuremath{\bm{\w}}_1^\ensuremath{\top} \\ & \tilde{U}_2 \end{bmatrix} \ccr
= \underbrace{\begin{bmatrix}
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1\\
1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0
\end{bmatrix}}_{P^\ensuremath{\top}}   \underbrace{\begin{bmatrix}1 \\
1/3 & 1 \\ 
0 &  0 & 1 \\
1& 1/5 & -2/3 & 1 \end{bmatrix}}_{L} \underbrace{\begin{bmatrix} 
 3 & 3 &3 & 0\\
  &5  & 5 & 5 \\
   && 3 & 1 \\
 &  && -2/3 
 \end{bmatrix}}_{U}
}
\textbf{END}

\rule{\textwidth}{1pt}
\textbf{Problem 2} By computing the Cholesky factorisation, determine which of the following matrices are symmetric positive definite:
\[
\begin{bmatrix} 1 & -1  \\
-1 & 3
\end{bmatrix}, \begin{bmatrix} 1 & 2 & 2  \\
2 & 1 & 2\\
2 & 2 & 1
\end{bmatrix},
\begin{bmatrix} 4 & 2 & 2 & 1  \\
2 & 4 & 2 & 2\\
2 & 2 & 4 & 2 \\
1 & 2 & 2 & 4
\end{bmatrix}
\]
\textbf{SOLUTION}

A matrix is symmetric positive definite (SPD) if and only if it has a Cholesky factorisation, so the task here is really just to compute Cholesky factorisations (by hand). Since our goal is to tell if the Cholesky factorisations exist, we do not have to compute $L_k$'s. We only need to see if the factorisation process can continue to the end.

\emph{Matrix 1}
\[
A_0=\begin{bmatrix} 1 & -1  \\
-1 & 3
\end{bmatrix}
\]
and     $A_1=3-\frac{(-1)\ensuremath{\times}(-1)}{1}>0$, so Matrix 1 is SPD.

\emph{Matrix 2}
\[
A_0=\begin{bmatrix}
1 & 2 & 2 \\
2 & 1 & 2 \\
2 & 2 & 1
\end{bmatrix}
\]
Then
\[
A_1=\begin{bmatrix}
1&2\\
2&1
\end{bmatrix}-\begin{bmatrix} 2 \\ 2 \end{bmatrix}\begin{bmatrix} 2 & 2 \end{bmatrix}=
\begin{bmatrix}
-3&-2\\
-2&-3
\end{bmatrix}
\]
and finally $A_1[1,1] \ensuremath{\leq} 0$, so Matrix 2 is not SPD.

\emph{Matrix 3}
\[
A_0=\begin{bmatrix}
4 & 2 & 2 & 1 \\
2 & 4 & 2 & 2 \\
2 & 2 & 4 & 2 \\
1 & 2 & 2 & 4
\end{bmatrix}
\]
and then
\[
A_1=\begin{bmatrix}
4&2&2\\
2&4&2\\
2&2&4
\end{bmatrix}-\frac{1}{4}\begin{bmatrix} 2 \\ 2 \\ 1 \end{bmatrix}\begin{bmatrix} 2 & 2 & 1 \end{bmatrix}=\frac{1}{4}
\begin{bmatrix}
12&4&6\\
4&12&6\\
6&6&15
\end{bmatrix}
\]
Furthermore
\[
4A_2=\begin{bmatrix}
12&6\\
6&15
\end{bmatrix}-\frac{1}{12}\begin{bmatrix} 4 \\ 6 \end{bmatrix}\begin{bmatrix} 4 & 6 \end{bmatrix}=\frac{4}{3}
\begin{bmatrix}
8&3\\
3&9
\end{bmatrix}
\]
and finally $3A_3=9-\frac{3\ensuremath{\times} 3}{8}>0$, so Matrix 4 is SPD.

\textbf{END}

\textbf{Problem 3} Show that a matrix $A \ensuremath{\in} \ensuremath{\bbR}^{n \ensuremath{\times} n}$ is symmetric positive definite if and only if it has a \emph{reverse} Cholesky factorisation of the form
\[
A = U U^\ensuremath{\top}
\]
where $U$ is upper triangular with positive entries on the diagonal.

\textbf{SOLUTION}

Note $\ensuremath{\bm{\x}}^\ensuremath{\top} U U^\ensuremath{\top} \ensuremath{\bm{\x}} = \| U^\ensuremath{\top} \ensuremath{\bm{\x}} \| > 0$ since $U$ is invertible.

For the other direction, we replicate the proof by induction for standard Cholesky, beginning in the bottom right instead of the top left. Again the basis case is trivial. Since all diagonal entries are positive we can write
\[
A = \begin{bmatrix} K & \ensuremath{\bm{\v}}\\
                    \ensuremath{\bm{\v}}^\ensuremath{\top} & \ensuremath{\alpha} \end{bmatrix} =
                    \underbrace{\begin{bmatrix} I & {\ensuremath{\bm{\v}} \over \sqrt{\ensuremath{\alpha}}} \\
                                        & \sqrt{\ensuremath{\alpha}}
                                        \end{bmatrix}}_{U_1}
                    \begin{bmatrix} K - {\ensuremath{\bm{\v}} \ensuremath{\bm{\v}}^\ensuremath{\top} \over \ensuremath{\alpha}}  & \\
                     & 1 \end{bmatrix}
                     \underbrace{\begin{bmatrix} I \\
                      {\ensuremath{\bm{\v}}^\ensuremath{\top} \over \sqrt{\ensuremath{\alpha}}} & \sqrt{\ensuremath{\alpha}}
                                        \end{bmatrix}}_{U_1^\ensuremath{\top}}
\]
By assumption $K - {\ensuremath{\bm{\v}} \ensuremath{\bm{\v}}^\ensuremath{\top} \over \ensuremath{\alpha}} = \Ut\Ut^\ensuremath{\top}$ hence we have
\[
A = \underbrace{U_1 \begin{bmatrix} \Ut \\ & 1 \end{bmatrix}}_U  \underbrace{\begin{bmatrix} \Ut^\top \\ & 1 \end{bmatrix} U_1^\top}_{U^\top}
\]
\textbf{END}

\textbf{Problem 4(a)} Use the Cholesky factorisation to prove that the following $n \ensuremath{\times} n$ matrix is symmetric positive definite for any $n$:
\[
\ensuremath{\Delta}_n := \begin{bmatrix}
2 & -1 \\
-1 & 2 & -1 \\
& -1 & 2 & \ensuremath{\ddots} \\
&& \ensuremath{\ddots} & \ensuremath{\ddots} & -1 \\
&&& -1 & 2
\end{bmatrix}
\]
Hint: consider a matrix $K_n^{(\ensuremath{\alpha})}$ that equals $\ensuremath{\Delta}_n$ apart from the top left entry which is $\ensuremath{\alpha} > 1$ and use a proof by induction.

\textbf{SOLUTION}

Consider the first step of the Cholesky factorisation:
\[
\ensuremath{\Delta}_n = \begin{bmatrix} 2 & -\ensuremath{\bm{\e}}_1^\ensuremath{\top} \\
                    -\ensuremath{\bm{\e}}_1 & \ensuremath{\Delta}_{n-1} \end{bmatrix} =
                    \underbrace{\begin{bmatrix} \sqrt{2} \\
                                    {-\ensuremath{\bm{\e}}_1 \over \sqrt{2}} & I
                                        \end{bmatrix}}_{L_1}
                    \begin{bmatrix}1 \\ & \ensuremath{\Delta}_{n-1} - {\ensuremath{\bm{\e}}_1 \ensuremath{\bm{\e}}_1^\ensuremath{\top} \over 2} \end{bmatrix}
                    \underbrace{\begin{bmatrix} \sqrt{2} & {-\ensuremath{\bm{\e}}_1^\ensuremath{\top} \over \sqrt{2}} \\
                                                            & I
                                        \end{bmatrix}}_{L_1^\ensuremath{\top}}
\]
The bottom right is merely $\ensuremath{\Delta}_{n-1}$ but with a different $(1,1)$ entry! This hints at a strategy of proving by induction.

Assuming $\ensuremath{\alpha} > 1$ write
\[
K_n^{(\ensuremath{\alpha})} := \begin{bmatrix}
\ensuremath{\alpha} & -1 \\
-1 & 2 & -1 \\
& -1 & 2 & \ensuremath{\ddots} \\
&& \ensuremath{\ddots} & \ensuremath{\ddots} & -1 \\
&&& -1 & 2
\end{bmatrix} =
                    \begin{bmatrix} \sqrt{\ensuremath{\alpha}} \\
                                    {-\ensuremath{\bm{\e}}_1 \over \sqrt{\ensuremath{\alpha}}} & I
                                        \end{bmatrix}
                    \begin{bmatrix}1 \\ & K_{n-1}^{(2 - 1/\ensuremath{\alpha})} \end{bmatrix}
                    \begin{bmatrix} \sqrt{\ensuremath{\alpha}} & {-\ensuremath{\bm{\e}}_1^\ensuremath{\top} \over \sqrt{\ensuremath{\alpha}}} \\
                                                            & I
                                        \end{bmatrix}
\]
Note if $n = 1$ this is trivially SPD. Hence assume $K_{n-1}^{(\ensuremath{\alpha})}$ is SPD for all $\ensuremath{\alpha} > 1$. If $\ensuremath{\alpha} > 1$ then $2 - 1/\ensuremath{\alpha} > 1$. Hence by induction and the fact that $\ensuremath{\Delta}_n = K_n^{(2)}$ we conclude that $\ensuremath{\Delta}_n$ has a Cholesky factorisation and hence is symmetric positive definite.

\textbf{END}

\textbf{Problem 4(b)} Deduce its Cholesky factorisations: $\ensuremath{\Delta}_n = L_n L_n^\ensuremath{\top}$ where $L_n$ is lower triangular.

\textbf{SOLUTION}

We can  write down the factors explicitly: define $\ensuremath{\alpha}_1 := 2$ and
\[
\ensuremath{\alpha}_{k+1} = 2- 1/\ensuremath{\alpha}_k.
\]
Let's try out the first few:
\[
\ensuremath{\alpha}_1 = 2, \ensuremath{\alpha}_2 = 3/2, \ensuremath{\alpha}_3 = 4/3, \ensuremath{\alpha}_4 = 5/4, \ensuremath{\ldots}
\]
The pattern is clear and one can show by induction that $\ensuremath{\alpha}_k = (k+1)/k$. Thus we have the Cholesky factorisation
\meeq{
\ensuremath{\Delta} _n = \underbrace{\begin{bmatrix}
\sqrt{2} \\
-1/\sqrt{2} & \sqrt{3/2} \\
& -\sqrt{2/3} & \sqrt{4/3} \\
    && \ensuremath{\ddots} & \ensuremath{\ddots} \\
    &&& -\sqrt{(n-1)/n} & \sqrt{(n+1)/n}
    \end{bmatrix}}_{L_n}  \\
    & \qquad \ensuremath{\times}     \underbrace{\begin{bmatrix}
\sqrt{2} & -1/\sqrt{2} \\
 & \sqrt{3/2} & -\sqrt{2/3} \\
    && \ensuremath{\ddots} & \ensuremath{\ddots} \\
    &&& \sqrt{n/(n-1)} & -\sqrt{(n-1)/n} \\
    &&&& \sqrt{(n+1)/n}
    \end{bmatrix}}_{L_n^\ensuremath{\top}}
}
\textbf{END}



\end{document}