
\section{Differential Equations via Finite Differences}
Linear algebra is a powerful tool for solving linear equations, including \ensuremath{\infty}-dimensional ones like differential equations. In this section we discuss \emph{finite differences}: an algorithmic way of reducing ODEs to linear systems by replacing derivatives with divided difference approximations. 

We will focus on the following differential equations. Indefinite integration for $a \ensuremath{\leq} x \ensuremath{\leq} b$ can be viewed as solving a very simple first-order linear ODE: given a constant $c \ensuremath{\in} \ensuremath{\bbF}$ (where  $\ensuremath{\bbF}$ is either $\ensuremath{\bbR}$ or $\ensuremath{\bbC}$) and a function $f : [a,b] \ensuremath{\rightarrow} \ensuremath{\bbF}$, find a differentiable function $u : [a,b] \ensuremath{\rightarrow} \ensuremath{\bbF}$ such that
\meeq{
u(a) = c, \ccr
u'(x) = f(x).
}
We will then allow for more complicated first order linear ODEs with variable coefficients: given  a constant $c$ and functions $f,\ensuremath{\omega} : [a,b] \ensuremath{\rightarrow} \ensuremath{\bbF}$ find $u$ such that
\meeq{
u(a) = c, \ccr 
u'(x) - \ensuremath{\omega}(x) u(x) = f(x).
}
For second-order differential equations you may have seen \emph{initial value problems} where the value and derivative at an initial point $x=a$ are provided.  Instead, we will consider \emph{boundary value problems} where the value at the left and right endpoints are imposed. In particular we will consider the Poisson equation with \emph{Dirichlet conditions} (i.e. conditions on the left and right of an interval): given constants $c,d$ and a function $f$ find a twice-differentiable function $u$ such that
\meeq{
u(a) = c, \ccr
u''(x) = f(x), \ccr
u(b) = d
}
In higher dimensions, the Poisson equation (and other \emph{elliptic} partial differential equations) typically have boundary conditions imposed on the boundary of a complicated geometry, and give the temperature equilibrium of a plate where the temperature is held fixed. The techniques we discuss for our simple 1D model problem extend to these more challenging settings.

Briefly, the basic idea of finite differences is a systematic way of reducing a differential equation to a linear system. For each problem we will do the following steps:

\begin{itemize}
\item[1. ] Discretise the interval $[a,b]$ by a grid of points $x_0,\ensuremath{\ldots},x_n$ and write the ODE on each grid point.


\item[2. ] Replace true derivatives of the solution $u$ with approximate derivatives in terms of values on the grid $u(x_j)$ via the divided difference formula.


\item[3. ] In the formula replace unknown values of $u(x_j)$ at the grid by new unknowns $u_j$.


\item[4. ] Deduce from this  a linear system that can be solved to compute $u_j$ so that (hopefully) $u_j \ensuremath{\approx} u(x_j)$. 

\end{itemize}
\textbf{Remark} There is a rich theory proving convergence of finite difference approximations to the true solution of ODEs but this is beyond the scope of this module, instead, we just learn the recipe. In the lab we determine convergence rates experimentally.

\subsection{Indefinite integration}
We begin with the simplest differential equation on an interval $[a,b]$:
\begin{align*}
u(a) &= c, \\
u'(x) &= f(x)
\end{align*}
As in integration we will use an evenly spaced grid $a = x_0 < x_1 < \ensuremath{\ldots} < x_n = b$ defined by $x_j :=  a + h j$ where $h := (b-a)/n$. The solution is of course $u(x) = c + \ensuremath{\int}_a^x f(x) {\rm d}x$ and we could use Rectangular or Trapezium rules  to obtain approximations to $u(x_j)$ for each $j$, however, we shall take another approach that will generalise to other differential equations. 

Consider a divided difference approximation like right-sided divided differences: 
\[
u'(x) \ensuremath{\approx} {u(x+h) - u(x)\over h}.
\]
When applied to a grid point $x_j \ensuremath{\in} \set{x_0,\ensuremath{\ldots},x_{n-1}}$ this becomes:
\[
u'(x_j) \ensuremath{\approx} {u(x_j+h) - u(x_j)\over h} = {u(x_{j+1}) - u(x_j)\over h}
\]
Note that $x_n$ is not permitted since that would depend on $u(x_{n+1})$, but $x_{n+1} > b$ and we have only assumed $f$ is defined on $[a,b]$. We use this approximation as follows:

(1) Write the ODE and initial conditions on the grid. Since right-sided divided differences will depend on $x_j$ and $x_{j+1}$ we stop at $x_{n-1}$ to avoid going past our grid: 
\[
\Vectt[u(x_0) , 
     u'(x_0) ,
u'(x_1) ,
\ensuremath{\vdots} ,
u'(x_{n-1})] = \underbrace{\Vectt[c, f(x_0), f(x_1), \ensuremath{\vdots} , f(x_{n-1})]}_{\ensuremath{\bm{\b}}}
\]
(2) Replace derivatives with divided differences, changing equality to an approximation:
\[
\Vectt[u(x_0) \\ 
(u(x_1) - u(x_0))/h \\
(u(x_2) - u(x_1))/h \\
\ensuremath{\vdots} \\
(u(x_n) - u(x_{n-1})/h] \ensuremath{\approx} \ensuremath{\bm{\b}}
\]
(3) We do not know $u(x_j)$ hence we replace it with other unknowns $u_j$, but where the approximation is turned back into an equality: we want to find $u_0,\ensuremath{\ldots},u_n$ such that
\[
\Vectt[u_0 \\ 
(u_1 - u_0)/h \\
(u_2 - u_1)/h \\
\ensuremath{\vdots} \\
(u_n - u_{n-1})/h] = \ensuremath{\bm{\b}}
\]
(4) This can be rewritten as a lower bidiagonal linear system:
\[
\underbrace{\begin{bmatrix}
    1 \\ 
    -1/h & 1/h \\
    & \ensuremath{\ddots} & \ensuremath{\ddots} \\
    && -1/h & 1/h \end{bmatrix}}_L \underbrace{\Vectt[u_0,u_1,\ensuremath{\vdots},u_n]}_{\ensuremath{\bm{\u}}} = \ensuremath{\bm{\b}}
\]
We can determine $\ensuremath{\bm{\u}}$ by solving $L \ensuremath{\bm{\u}} = \ensuremath{\bm{\b}}$ using forward-substitution.

As mentioned before, it is possible to prove that as $n \ensuremath{\rightarrow} \ensuremath{\infty}$ we have for all $j$ that $u_j \ensuremath{\rightarrow} u(x_j)$ (uniformly). But we will leave this to be shown experimentally in the lab.

\subsection{Forward Euler}
We can extend this to more general first-order linear differential equations with a variable coefficient:
\begin{align*}
u(a) &= c \\
u'(x) + \ensuremath{\omega}(x) u(x) &= f(x)
\end{align*}
The steps proceed very similar to before:

(1) Write the ODE and initial conditions on the grid, avoiding $x_n$ so that we don't go past the endpoint:
\[
\Vectt[u(x_0) \\ 
u'(x_0) + \ensuremath{\omega}(x_0) u(x_0) \\
u'(x_1) + \ensuremath{\omega}(x_1) u(x_1) \\
\ensuremath{\vdots} \\
u'(x_{n-1})+ \ensuremath{\omega}(x_{n-1}) u(x_{n-1})] = \underbrace{\Vectt[c, f(x_0), f(x_1), \ensuremath{\vdots} , f(x_{n-1})]}_{\ensuremath{\bm{\b}}}
\]
(2) Replace derivatives with divided differences:
\[
\Vectt[u(x_0) \\ 
(u(x_1) - u(x_0))/h + \ensuremath{\omega}(x_0)u(x_0) \\
(u(x_2) - u(x_1))/h + \ensuremath{\omega}(x_1)u(x_1) \\
\ensuremath{\vdots} \\
(u(x_n) - u(x_{n-1}))/h + \ensuremath{\omega}(x_{n-1})u(x_{n-1})] \ensuremath{\approx} \ensuremath{\bm{\b}}
\]
(3) Replace $u(x_j)$  by its approximation $u_j$ but now with the system being an equality:
\[
\Vectt[u_0 \\ 
(u_1 - u_0)/h + \ensuremath{\omega}(x_0) u_0 \\
(u_2 - u_1)/h + \ensuremath{\omega}(x_1) u_1 \\
\ensuremath{\vdots} \\
(u_n - u_{n-1})/h  + \ensuremath{\omega}(x_{n-1}) u_{n-1}] = \ensuremath{\bm{\b}}
\]
(4) This is equivalent to the linear system:
\[
\underbrace{\begin{bmatrix}
    1 \\ 
    \ensuremath{\omega}(x_0)-1/h & 1/h \\
    & \ensuremath{\ddots} & \ensuremath{\ddots} \\
    && \ensuremath{\omega}(x_{n-1})-1/h & 1/h \end{bmatrix}}_L \underbrace{\Vectt[u_0,u_1,\ensuremath{\vdots},u_n]}_{\ensuremath{\bm{\u}}} = \ensuremath{\bm{\b}}
\]
We can solve $L \ensuremath{\bm{\u}} = \ensuremath{\bm{\b}}$ using forward-substitution so that $u_j \ensuremath{\approx} u(x_j)$.

\subsection{Poisson equation}
Consider the Poisson equation with Dirichlet conditions (a two-point boundary value problem): given constants $c,d$ and a function $f : [a,b] \ensuremath{\rightarrow} \ensuremath{\bbR}$ find a twice differentiable function $u : [a,b] \ensuremath{\rightarrow} \ensuremath{\bbR}$ satisfying
\begin{align*}
u(a) &= c, \\
u''(x) &= f(x), \\
u(b) &= d
\end{align*}
We shall adapt the procedure using the second-order divided difference approximation from the first probem sheet:
\[
u''(x) \ensuremath{\approx} {u(x-h) - 2u(x) + u(x+h)\over h^2}
\]
When applied to a grid point $x_1,\ensuremath{\ldots},x_{n-1}$ this becomes:
\[
u'(x_j) \ensuremath{\approx} {u(x_j-h) - 2u(x_j) + u(x_j+h)\over h^2} = {u(x_{j-1}) - 2u(x_j) + u(x_{j+1})\over h^2}
\]
Note that $x_0$ and $x_n$ are not permitted since that would go past the endpoints of the interval. We use this approximation as follows:

(1) Write the ODE and boundary conditions on the grid (putting the left condition on the top and right condition on the bottom):
\[
\Vectt[u(x_0) \\ 
u''(x_1) \\
u''(x_2) \\
\ensuremath{\vdots} \\
u''(x_{n-1}) \\
u(x_n)] = \underbrace{\Vectt[c, f(x_1), f(x_2), \ensuremath{\vdots} , f(x_{n-1}), d]}_{\ensuremath{\bm{\b}}}
\]
(2) Replace derivatives with divided differences:
\[
\Vectt[u(x_0) \\ 
{u(x_0) - 2u(x_1) + u(x_2)\over h^2} \\
{u(x_1) - 2u(x_2) + u(x_3)\over h^2} \\
\ensuremath{\vdots} \\
{u(x_{n-2}) - 2u(x_{n-1}) + u(x_n)\over h^2} \\
u(x_n)] \ensuremath{\approx} \ensuremath{\bm{\b}}
\]
(3) Replace $u(x_j)$  by its approximation $u_j$: we want to find $u_0,\ensuremath{\ldots},n_n$ so that
\[
\Vectt[u_0 \\ 
{u_0 - 2u_1 + u_2\over h^2} \\
{u_1 - 2u_2 + u_3\over h^2} \\
\ensuremath{\vdots} \\
{u_{n-2} - 2u_{n-1} + u_n\over h^2} \\
u_n] = \ensuremath{\bm{\b}}
\]
(4) This is equivalent to a tridiagonal linear system:
\[
\underbrace{\begin{bmatrix}
    1 \\ 
    1/h^2 & -2/h^2 & 1/h^2 \\
    & \ensuremath{\ddots} & \ensuremath{\ddots} & \ensuremath{\ddots} \\
   && 1/h^2 & -2/h^2 & 1/h^2 \\ 
   &&&& 1 \end{bmatrix}}_A \underbrace{\Vectt[u_0,u_1,\ensuremath{\vdots},u_n]}_{\ensuremath{\bm{\u}}} = \ensuremath{\bm{\b}}
\]
This can be solved in $O(n)$ complexity using a banded LU or QR factorisation.



