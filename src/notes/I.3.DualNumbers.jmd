# Dual Numbers

In this section we introduce a mathematically beautiful  alternative to divided differences for computing
derivatives: _dual numbers_. These are a commutative ring that _exactly_ compute derivatives,
which when implemented on a computer gives very high-accuracy approximations to derivatives. They
underpin forward-mode [automatic differentation](https://en.wikipedia.org/wiki/Automatic_differentiation).
Automatic differentiation  is a basic tool in Machine Learning for computing gradients necessary
for training neural networks.


**Definition (Dual numbers)** Dual numbers $𝔻$ are a commutative ring (over $ℝ$)
generated by $1$ and $ϵ$ such that $ϵ^2 = 0$.
Dual numbers are typically written as $a + b ϵ$ where $a$ and $b$ are real.
∎

This is very much analoguous to complex numbers, which are a field generated by $1$ and $\I$ such that
$\I^2 = -1$. Compare multiplication of each number type:
$$
\meeq{
(a + b \I) (c + d \I) = ac + (bc + ad) \I + bd \I^2 = ac -bd + (bc + ad) \I \ccr
(a + b ϵ) (c + d ϵ) = ac + (bc + ad) ϵ + bd ϵ^2 = ac  + (bc + ad) ϵ 
}
$$
And just as we view $ℝ ⊂ ℂ$ by equating $a ∈ ℝ$ with $a + 0\I ∈ ℂ$,
we can view $ℝ ⊂ 𝔻$ by equating $a ∈ ℝ$ with $a + 0{\rm ϵ} ∈ 𝔻$.

## Differentiating polynomials

Polynomials evaluated on dual numbers are well-defined as
they depend only on the operations $+$ and $*$. From the formula for multiplication of dual numbers
we deduce that evaluating a polynomial at a dual number $a + b ϵ$ tells us the derivative of the polynomial at $a$:

**Theorem (polynomials on dual numbers)** Suppose $p$ is a polynomial. Then
$$
p(a + b ϵ) = p(a) + b p'(a) ϵ
$$

**Proof**

First consider $p(x) = x^n$ for $n ≥ 0$. 
The cases $n = 0$ and $n = 1$ are immediate. For $n > 1$ we have by induction:
$$
(a + b ϵ)^n = (a + b ϵ) (a + b ϵ)^{n-1} = (a + b ϵ) (a^{n-1} + (n-1) b a^{n-2} ϵ) = a^n + b n a^{n-1} ϵ.
$$
For a more general polynomial
$$
p(x) = ∑_{k=0}^n c_k x^k
$$
the result follows from linearity:
$$
p(a + b ε) = ∑_{k=0}^n c_k (a+bϵ)^k = c_0 + ∑_{k=1}^n c_k (a^k +k b a^{k-1}ϵ)
= ∑_{k=0}^n c_k a^k + b ∑_{k=1}^n c_k k a^{k-1}ϵ = p(a) + b p'(a) ϵ.
$$

∎

**Example (differentiating polynomial)** Consider computing $p'(2)$ where
$$
p(x) = (x-1)(x-2) + x^2.
$$
We can use dual numbers to differentiate, avoiding expanding in monomials
or applying rules of differentiating:
$$
p(2+ϵ) = (1+ϵ)ϵ + (2+ϵ)^2 = ϵ + 4 + 4ϵ = 4 + \underbrace{5}_{p'(2)}ϵ
$$
∎


## Differentiating other functions


We can extend real-valued differentiable functions to dual numbers in a similar manner.
First, consider a standard function with a Taylor series (e.g. ${\rm cos}$, ${\rm sin}$, ${\rm exp}$, etc.)
$$
f(x) = ∑_{k=0}^∞ f_k x^k
$$
so that $a$ is inside the radius of convergence. This leads naturally to a definition on dual numbers:
$$
\meeq{
f(a + b ϵ) = ∑_{k=0}^∞ f_k (a + b ϵ)^k = f_0 + ∑_{k=1}^∞ f_k (a^k + k a^{k-1} b ϵ) = ∑_{k=0}^∞ f_k a^k +  ∑_{k=1}^∞ f_k k a^{k-1} b ϵ  \ccr
  = f(a) + b f'(a) ϵ
}
$$
More generally, given a differentiable function we can extend it to dual numbers:

**Definition (dual extension)** Suppose a real-valued function $f$
is differentiable at $a$. We can extend the definition of $f$ to dual numbers
via
$$
f(a + b ϵ) := f(a) + b f'(a) ϵ,
$$
in which case we say that $f$ is _dual-extended_ at $a$.


Thus, for basic functions we have natural extensions:
$$
\begin{align*}
\exp(a + b ϵ) &:= \exp(a) + b \exp(a) ϵ \\
\sin(a + b ϵ) &:= \sin(a) + b \cos(a) ϵ \\
\cos(a + b ϵ) &:= \cos(a) - b \sin(a) ϵ \\
\log(a + b ϵ) &:= \log(a) + {b \over a} ϵ \\
\sqrt{a+b ϵ} &:= \sqrt{a} + {b \over 2 \sqrt{a}} ϵ \\
|a + b ϵ| &:= |a| + b\, {\rm sign} a\, ϵ
\end{align*}
$$
provided the function is differentiable at $a$. Note the last example does not have
a convergent Taylor series (at 0) but we can still extend it where it is differentiable.

Going further, we can add, multiply, and compose such functions:

**Lemma (product and chain rule)**
Suppose $f$ is dual-extended at $g(a)$ and $g$ is dual-extended at $a$. Then
$q(x) := f(g(x))$ is automatically dual-extended at $a$.
If $f$ and $g$ are dual-extended at $a$ then 
$r(x) := f(x) g(x)$ is also automatically dual-extended at $a$. In other words:
$$
\meeq{
q(a+b ϵ) = q(a) + b q'(a) ϵ \ccr
r(a+b ϵ) = r(a) + b r'(a) ϵ
}
$$

**Proof**
For $q$ it follows immediately:
$$
\meeq{
q(a + b ϵ) = f(g(a + b ϵ)) = f(g(a) + b g'(a) ϵ) \ccr
= f(g(a)) + b g'(a) f'(g(a))ϵ = q(a) + b q'(a) ϵ.
}
$$
For $r$ we have
$$
\meeq{
r(a + b ϵ) = f(a+b ϵ )g(a+b ϵ )= (f(a) + b f'(a) ϵ)(g(a) + b g'(a) ϵ) \ccr
= f(a)g(a) + b (f'(a)g(a) + f(a)g'(a)) ϵ = r(a) +b r'(a) ϵ.
}
$$

∎

A simple corollary is that any function defined in terms of addition, multiplication, composition, etc.
of functions that are dual with differentiation will be differentiable via dual numbers.

**Example (differentiating non-polynomial)**

Consider differentiating $f(x) =  \exp(x^2 + \E^x)$ at the point $a = 1$ by evaluating on the duals:
$$
f(1 + ϵ) = \exp(1 + 2ϵ + \E + \E ϵ) =  \exp(1 + \E) + \exp(1 + \E) (2 + \E) ϵ.
$$
Therefore we deduce that
$$
f'(1) = \exp(1 + \E) (2 + \E).
$$

∎

