
\section{Discrete Fourier Transform}
In the previous section we explored using the trapezium rule for approximating Fourier coefficients. This is a linear map from function values to coefficients and thus can be reinterpreted as a matrix-vector product, called the the Discrete Fourier Transform. It turns out the matrix is unitary which leads to important properties including interpolation. 

\textbf{Remark} A clever way of decomposing the DFT leads to a fast way of applying and inverting it, which is one of the most influencial algorithms of the 20th century: the Fast Fourier Transform. But this is beyond the scope of this module.

\subsection{The Discrete Fourier transform}
\begin{definition}[DFT] The \emph{Discrete Fourier Transform (DFT)} is defined as:
\begin{align*}
Q_n &:= {1 \over \sqrt{n}} \begin{bmatrix} 1 & 1 & 1&  \ensuremath{\cdots} & 1 \\
                                    1 & {\rm e}^{-\I \ensuremath{\theta}_1} & {\rm e}^{-\I \ensuremath{\theta}_2} & \ensuremath{\cdots} & {\rm e}^{-\I \ensuremath{\theta}_{n-1}} \\
                                    1 & {\rm e}^{-\I 2 \ensuremath{\theta}_1} & {\rm e}^{-\I 2 \ensuremath{\theta}_2} & \ensuremath{\cdots} & {\rm e}^{-\I 2\ensuremath{\theta}_{n-1}} \\
                                    \ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\ddots} & \ensuremath{\vdots} \\
                                    1 & {\rm e}^{-\I (n-1) \ensuremath{\theta}_1} & {\rm e}^{-\I (n-1) \ensuremath{\theta}_2} & \ensuremath{\cdots} & {\rm e}^{-\I (n-1) \ensuremath{\theta}_{n-1}}
\end{bmatrix} \\
&= {1 \over \sqrt{n}} \begin{bmatrix} 1 & 1 & 1&  \ensuremath{\cdots} & 1 \\
                                    1 & \ensuremath{\omega}^{-1} & \ensuremath{\omega}^{-2} & \ensuremath{\cdots} & \ensuremath{\omega}^{-(n-1)}\\
                                    1 & \ensuremath{\omega}^{-2} & \ensuremath{\omega}^{-4} & \ensuremath{\cdots} & \ensuremath{\omega}^{-2(n-1)}\\
                                    \ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\ddots} & \ensuremath{\vdots} \\
                                    1 & \ensuremath{\omega}^{-(n-1)} & \ensuremath{\omega}^{-2(n-1)} & \ensuremath{\cdots} & \ensuremath{\omega}^{-(n-1)^2}
\end{bmatrix}
\end{align*}
for the $n$-th root of unity $\ensuremath{\omega} = {\rm e}^{2\ensuremath{\pi}\I/n}$.  \end{definition}

Note that
\begin{align*}
Q_n^\ensuremath{\star} &= {1 \over \sqrt{n}} \begin{bmatrix}
1 & 1 & 1&  \ensuremath{\cdots} & 1 \\
1 & {\rm e}^{\I \ensuremath{\theta}_1} & {\rm e}^{\I 2 \ensuremath{\theta}_1} & \ensuremath{\cdots} & {\rm e}^{\I (n-1) \ensuremath{\theta}_1} \\
1 &  {\rm e}^{\I \ensuremath{\theta}_2}  & {\rm e}^{\I 2 \ensuremath{\theta}_2} & \ensuremath{\cdots} & {\rm e}^{\I (n-1)\ensuremath{\theta}_2} \\
\ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\ddots} & \ensuremath{\vdots} \\
1 & {\rm e}^{\I \ensuremath{\theta}_{n-1}} & {\rm e}^{\I 2 \ensuremath{\theta}_{n-1}} & \ensuremath{\cdots} & {\rm e}^{\I (n-1) \ensuremath{\theta}_{n-1}}
\end{bmatrix} \\
&= {1 \over \sqrt{n}} \begin{bmatrix}
1 & 1 & 1&  \ensuremath{\cdots} & 1 \\
1 & \ensuremath{\omega}^{1} & \ensuremath{\omega}^{2} & \ensuremath{\cdots} & \ensuremath{\omega}^{(n-1)}\\
1 & \ensuremath{\omega}^{2} & \ensuremath{\omega}^{4} & \ensuremath{\cdots} & \ensuremath{\omega}^{2(n-1)}\\
\ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\ddots} & \ensuremath{\vdots} \\
1 & \ensuremath{\omega}^{(n-1)} & \ensuremath{\omega}^{2(n-1)} & \ensuremath{\cdots} & \ensuremath{\omega}^{(n-1)^2}
\end{bmatrix}
\end{align*}
Hence we have
\[
\underbrace{\begin{bmatrix} \hat f_0^n \\ \ensuremath{\vdots} \\ \hat f_{n-1}^n \end{bmatrix}}_{\vchatf^n} =
{1 \over \sqrt{n}} Q_n \underbrace{\begin{bmatrix} f(\ensuremath{\theta}_0) \\ \ensuremath{\vdots} \\ f(\ensuremath{\theta}_{n-1}) \end{bmatrix}}_{\ensuremath{\bm{\f}}^n}
\]
The choice of normalisation constant is motivated by the following:

\textbf{Proposition 1 (DFT is Unitary)} $Q_n \ensuremath{\in} U(n)$, that is, $Q_n^\ensuremath{\star} Q_n = Q_n Q_n^\ensuremath{\star} = I$.

\textbf{Proof}
\[
Q_n Q_n^\ensuremath{\star}  = \begin{bmatrix} \ensuremath{\Sigma}_n[1] & \ensuremath{\Sigma}_n[{\rm e}^{\I \ensuremath{\theta}}] & \ensuremath{\cdots} & \ensuremath{\Sigma}_n[{\rm e}^{\I (n-1) \ensuremath{\theta}}] \\
                            \ensuremath{\Sigma}_n[{\rm e}^{-\I \ensuremath{\theta}}] & \ensuremath{\Sigma}_n[1] & \ensuremath{\cdots} & \ensuremath{\Sigma}_n[{\rm e}^{\I (n-2) \ensuremath{\theta}}] \\
                            \ensuremath{\vdots} & \ensuremath{\vdots} & \ensuremath{\ddots} & \ensuremath{\vdots} \\
                            \ensuremath{\Sigma}_n[{\rm e}^{-\I(n-1) \ensuremath{\theta}}] & \ensuremath{\Sigma}_n[{\rm e}^{-\I(n-2) \ensuremath{\theta}}] & \ensuremath{\cdots} & \ensuremath{\Sigma}_n[1]
                            \end{bmatrix} = I
\]
\ensuremath{\QED}

In other words, $Q_n$ is easily inverted and we also have a map from discrete Fourier coefficients back to values:
\[
\sqrt{n} Q_n^\ensuremath{\star} \vchatf^n = \ensuremath{\bm{\f}}^n
\]
\begin{example}[Computing Sum] Define the following infinite sum (which has no name apparently, according to Mathematica):
\[
S_n(k) := \ensuremath{\sum}_{p=0}^\ensuremath{\infty} {1 \over (k+pn)!}
\]
We can use the DFT to compute $S_n(0), \ensuremath{\ldots}, S_n(n-1)$. Consider
\[
f(\ensuremath{\theta}) = \exp({\rm e}^{\I \ensuremath{\theta}}) = \ensuremath{\sum}_{k=0}^\ensuremath{\infty} {{\rm e}^{\I k \ensuremath{\theta}} \over k!}
\]
where we know the Fourier coefficients from the Taylor series of ${\rm e}^z$. The discrete Fourier coefficients satisfy for $0 \ensuremath{\leq} k \ensuremath{\leq} n-1$:
\[
\hat f_k^n = \hat f_k + \hat f_{k+n} + \hat f_{k+2n} + \ensuremath{\cdots} = S_n(k)
\]
Thus we have
\[
\begin{bmatrix}
S_n(0) \\
\ensuremath{\vdots} \\
S_n(n-1)
\end{bmatrix} = {1 \over \sqrt{n}} Q_n \begin{bmatrix} {\rm e} \\
                                \exp({\rm e}^{2\I \ensuremath{\pi}/n}) \\
                                \ensuremath{\vdots} \\
                                \exp({\rm e}^{2\I (n-1) \ensuremath{\pi}/n}) \end{bmatrix}
\]
\end{example}

\subsection{Interpolation}
We investigated  interpolation and least squares using polynomials at evenly spaced points, observing that there were issues with stability. We now show that the DFT actually gives coefficients that interpolate using Fourier expansions. As the DFT is a unitary matrix multiplication is \ensuremath{\ldq}stable", i.e. it preserves norms and hence we know it cannot cause the same huge blow-up we saw for polynomials. That is: whilst polynomials are bad for interpolation at evenly spaced points, trigonometric polynomials are great. 

The following guarantees that our approximate Fourier series actually interpolates the data:

\begin{corollary}[Interpolation]
\[
f_n(\ensuremath{\theta}) := \ensuremath{\sum}_{k=0}^{n-1} \hat f_k^n {\rm e}^{\I k \ensuremath{\theta}}
\]
interpolates $f$ at $\ensuremath{\theta}_j$:
\[
f_n(\ensuremath{\theta}_j) = f(\ensuremath{\theta}_j)
\]
\end{corollary}
\textbf{Proof} We have
\[
f_n(\ensuremath{\theta}_j) = \ensuremath{\sum}_{k=0}^{n-1} \hat f_k^n {\rm e}^{\I k \ensuremath{\theta}_j} = \sqrt n \ensuremath{\bm{\e}}_{j+1}^\ensuremath{\top} Q_n^\ensuremath{\star} \vchatf^n = \ensuremath{\bm{\e}}_{j+1}^\ensuremath{\top} Q_n^\ensuremath{\star} Q_n \ensuremath{\bm{\f}}^n = f(\ensuremath{\theta}_j).
\]
\ensuremath{\QED}

\begin{example}[DFT versus Lagrange] Consider interpolating $\exp z$ by a polynomial at the points $1, \I, -1, -\I$. We can use Lagrange polynomials:
\meeq{
\ensuremath{\ell}_1(z) ={ (z - \I)(z + 1)(z + \I) \over 2(1 - \I)(1 + \I)} = { z^3 + z^2 + z + 1 \over 4} \ccr
\ensuremath{\ell}_2(z) ={ (z - 1)(z + 1)(z + \I) \over (\I - 1) (\I + 1) 2\I} = { \I z^3 - z^2 - \I z + 1 \over 4} \ccr
\ensuremath{\ell}_3(z) ={ (z - 1)(z - \I)(z + \I) \over -2 (-1-\I)(-1+\I)} = {-z^3 + z^2 - z + 1 \over 4} \ccr
\ensuremath{\ell}_4(z) ={ (z - 1)(z - \I)(z+1) \over (-\I-1)(-2\I)(-\I+1)} = {- \I z^3 -z^2 + \I z + 1 \over 4}
}
So we get the interpolant:
\begin{align*}
\E & \ensuremath{\ell}_1(z) + \E^\I \ensuremath{\ell}_2(z) + \E^{-1} \ensuremath{\ell}_3(z) + \E^{-\I} \ensuremath{\ell}_4(z) \\
 &= 
{\E + \E^\I + \E^{-1} + \E^{-\I} \over 4} +
{\E - \I \E^\I - \E^{-1} + \I \E^{-\I} \over 4} z +
 {\E - \E^\I + \E^{-1} - \I \E^{-\I} \over 4} z^2 +
 {\E + \I \E^\I - \E^{-1} - \I \E^{-\I} \over 4} z^3 
\end{align*}
Alternatively we could have deduced this directly from the DFT. In particular, we know the coefficients of the interpolating polynomial must be, for $\ensuremath{\omega} = \I$ and $f(\ensuremath{\theta}) = \exp(\E^{\I \ensuremath{\theta}})$,
\[
\Vectt[\hat f_0^4, \hat f_1^4, \hat f_2^4, \hat f_3^4] = 
{1 \over 4} \begin{bmatrix}1 & 1 & 1 & 1 \\
                            1 & -\I & -1 & \I \\
                            1 & -1 & 1 & -1 \\
                            1 & \I & -1 & -\I
                            \end{bmatrix}
 \Vectt[\E, \E^\I, \E^{-1}, \E^{-\I}] = {1 \over 4} \Vectt[\E + \E^\I + \E^{-1} + \E^{-\I} ,
 \E -\I \E^\I - \E^{-1} + \I \E^{-\I} ,
 \E - \E^\I + \E^{-1} - \E^{-\I} ,
 \E + \I \E^\I - \E^{-1} - \I \E^{-\I}
 ] = {1 \over 2} \Vectt[\cosh 1 + \cos 1 ,
\sinh 1 + \sin 1 ,
 \cosh 1 - \cos 1 ,
 \sinh 1 - \sin 1
 ].
\]
\end{example}

The interpolation property also applies to the approximation
\[
f_n(\ensuremath{\theta}) = \ensuremath{\sum}_{k=-\ensuremath{\lceil}n/2\ensuremath{\rceil}}^{\ensuremath{\lfloor}n/2\ensuremath{\rfloor}} \hat f_k {\rm e}^{{\rm i} k \ensuremath{\theta}}
\]
for general Fourier series, which is investigated in the problem sheet.



