\documentclass[12pt,a4paper]{article}

\usepackage[a4paper,text={16.5cm,25.2cm},centering]{geometry}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage[usenames,dvipsnames]{xcolor}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1.2ex}




\hypersetup
       {   pdfauthor = {  },
           pdftitle={  },
           colorlinks=TRUE,
           linkcolor=black,
           citecolor=blue,
           urlcolor=blue
       }




\usepackage{upquote}
\usepackage{listings}
\usepackage{xcolor}
\lstset{
    basicstyle=\ttfamily\footnotesize,
    upquote=true,
    breaklines=true,
    breakindent=0pt,
    keepspaces=true,
    showspaces=false,
    columns=fullflexible,
    showtabs=false,
    showstringspaces=false,
    escapeinside={(*@}{@*)},
    extendedchars=true,
}
\newcommand{\HLJLt}[1]{#1}
\newcommand{\HLJLw}[1]{#1}
\newcommand{\HLJLe}[1]{#1}
\newcommand{\HLJLeB}[1]{#1}
\newcommand{\HLJLo}[1]{#1}
\newcommand{\HLJLk}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkc}[1]{\textcolor[RGB]{59,151,46}{\textit{#1}}}
\newcommand{\HLJLkd}[1]{\textcolor[RGB]{214,102,97}{\textit{#1}}}
\newcommand{\HLJLkn}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkp}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkr}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkt}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLn}[1]{#1}
\newcommand{\HLJLna}[1]{#1}
\newcommand{\HLJLnb}[1]{#1}
\newcommand{\HLJLnbp}[1]{#1}
\newcommand{\HLJLnc}[1]{#1}
\newcommand{\HLJLncB}[1]{#1}
\newcommand{\HLJLnd}[1]{\textcolor[RGB]{214,102,97}{#1}}
\newcommand{\HLJLne}[1]{#1}
\newcommand{\HLJLneB}[1]{#1}
\newcommand{\HLJLnf}[1]{\textcolor[RGB]{66,102,213}{#1}}
\newcommand{\HLJLnfm}[1]{\textcolor[RGB]{66,102,213}{#1}}
\newcommand{\HLJLnp}[1]{#1}
\newcommand{\HLJLnl}[1]{#1}
\newcommand{\HLJLnn}[1]{#1}
\newcommand{\HLJLno}[1]{#1}
\newcommand{\HLJLnt}[1]{#1}
\newcommand{\HLJLnv}[1]{#1}
\newcommand{\HLJLnvc}[1]{#1}
\newcommand{\HLJLnvg}[1]{#1}
\newcommand{\HLJLnvi}[1]{#1}
\newcommand{\HLJLnvm}[1]{#1}
\newcommand{\HLJLl}[1]{#1}
\newcommand{\HLJLld}[1]{\textcolor[RGB]{148,91,176}{\textit{#1}}}
\newcommand{\HLJLs}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsa}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsb}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsc}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsd}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsdB}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsdC}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLse}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLsh}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsi}[1]{#1}
\newcommand{\HLJLso}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsr}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLss}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLssB}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLnB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnbB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnfB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnh}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLni}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnil}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnoB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLoB}[1]{\textcolor[RGB]{102,102,102}{\textbf{#1}}}
\newcommand{\HLJLow}[1]{\textcolor[RGB]{102,102,102}{\textbf{#1}}}
\newcommand{\HLJLp}[1]{#1}
\newcommand{\HLJLc}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLch}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcm}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcp}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcpB}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcs}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcsB}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLg}[1]{#1}
\newcommand{\HLJLgd}[1]{#1}
\newcommand{\HLJLge}[1]{#1}
\newcommand{\HLJLgeB}[1]{#1}
\newcommand{\HLJLgh}[1]{#1}
\newcommand{\HLJLgi}[1]{#1}
\newcommand{\HLJLgo}[1]{#1}
\newcommand{\HLJLgp}[1]{#1}
\newcommand{\HLJLgs}[1]{#1}
\newcommand{\HLJLgsB}[1]{#1}
\newcommand{\HLJLgt}[1]{#1}


\def\endash{â€“}
\def\bbD{ {\mathbb D} }
\def\bbZ{ {\mathbb Z} }
\def\bbR{ {\mathbb R} }
\def\bbC{ {\mathbb C} }

\def\x{ {\vc x} }
\def\a{ {\vc a} }
\def\b{ {\vc b} }
\def\e{ {\vc e} }
\def\f{ {\vc f} }
\def\u{ {\vc u} }
\def\v{ {\vc v} }
\def\y{ {\vc y} }
\def\z{ {\vc z} }
\def\w{ {\vc w} }

\def\bt{ {\tilde b} }
\def\ct{ {\tilde c} }
\def\Ut{ {\tilde U} }
\def\Qt{ {\tilde Q} }
\def\Rt{ {\tilde R} }
\def\Xt{ {\tilde X} }
\def\acos{ {\rm acos}\, }

\def\red#1{ {\color{red} #1} }
\def\blue#1{ {\color{blue} #1} }
\def\green#1{ {\color{ForestGreen} #1} }
\def\magenta#1{ {\color{magenta} #1} }

\input{somacros}

\begin{document}



\textbf{Numerical Analysis MATH50003 (2024\ensuremath{\endash}25) Problem Sheet 3}

In this problem sheet we explore floating point numbers and bounding errors in arithmetic with rounding.  We begin with some simple examples of expressing real numbers in binary format and  representing them as floating point numbers:

\rule{\textwidth}{1pt}
\textbf{Problem 1} What is $\ensuremath{\pi}$ to 5 binary places? Hint: recall that $\ensuremath{\pi} \ensuremath{\approx} 3.14$.

\textbf{Problem 2} What are the single precision $F_{32} = F_{127,8,23}$ floating point representations for the following: 
\[
2, \quad 31, \quad 32, \quad 23/4, \quad (23/4)\times 2^{100}
\]
\rule{\textwidth}{1pt}
Floating point numbers cannot represent every real number. the next question explores the spacing between consecutive  floating point numbers:

\rule{\textwidth}{1pt}
\textbf{Problem 3} Let $m(y) = \min\{x \in F_{32} : x > y \}$ be the smallest single precision number greater than $y$. What is $m(2) - 2$ and $m(1024) - 1024$? 

\rule{\textwidth}{1pt}
Not every calculation involving floating point numbers has errors: sometimes they are exact. The next questions explore cases where they are exact, and where we have to round the number to represent them as a floating point number:

\rule{\textwidth}{1pt}
\textbf{Problem 4} Suppose $x = 1.25$ and consider 16-bit floating point arithmetic ($F_{16}$). What is the error in approximating $x$ by the nearest float point number ${\rm fl}(x)$? What is the error in approximating $2x$, $x/2$, $x + 2$ and $x - 2$ by $2 \otimes x$, $x \oslash 2$, $x \ensuremath{\oplus} 2$ and $x \ominus 2$?

\textbf{Problem 5} Show that $1/5 = 2^{-3} (1.1001100110011\ensuremath{\ldots})_2$. What are the exact bits for $1 \ensuremath{\oslash} 5$, $1 \ensuremath{\oslash} 5 \ensuremath{\oplus} 1$ computed using  half-precision arithmetic ($F_{16} := F_{15,5,10}$) (using default rounding)?

\rule{\textwidth}{1pt}
Arithmetic with floating point numbers is exact up to rounding and the \emph{round bound} gives a way of precisely bounding the errors involved. To simplify the discussion we use \emph{idealised floating point numbers} $F_{\ensuremath{\infty},S}$,  which avoids technicalities of subnormal numbers. We first see how error bounds can be deduced for two very simple expressions:

\rule{\textwidth}{1pt}
\textbf{Problem 6} Prove the following bounds on the \emph{absolute error} of a floating point calculation in idealised floating-point arithmetic $F_{\ensuremath{\infty},S}$ (i.e., you may assume all operations involve normal floating point numbers):
\begin{align*}
({\rm fl}(1.1) \ensuremath{\otimes} {\rm fl}(1.2)) &\ensuremath{\oplus} {\rm fl}(1.3) = 2.62 + \ensuremath{\varepsilon}_1 \\
({\rm fl}(1.1) \ensuremath{\ominus} 1) & \ensuremath{\oslash} {\rm fl}(0.1) = 1 + \ensuremath{\varepsilon}_2
\end{align*}
such that $|\ensuremath{\varepsilon}_1| \ensuremath{\leq} 11 \ensuremath{\epsilon}_{\rm m}$ and $|\ensuremath{\varepsilon}_2| \ensuremath{\leq} 40 \ensuremath{\epsilon}_{\rm m}$, where $\ensuremath{\epsilon}_{\rm m}$ is machine epsilon.

\rule{\textwidth}{1pt}
In the lectures/notes we saw how the effect of rounding errors in right-sided divided differences could be bounded.  Here we extend this to central differences which yields a different heuristic for the optimal choice of $h$:

\rule{\textwidth}{1pt}
\textbf{Problem 7(a)} Assume that $f^{\rm FP} : F_{\ensuremath{\infty},S} \ensuremath{\rightarrow} F_{\ensuremath{\infty},S}$ satisfies $f^{\rm FP}(x) = f(x) + \ensuremath{\delta}_x$ where $|\ensuremath{\delta}_x| \ensuremath{\leq} c \ensuremath{\epsilon}_{\rm m}$ for all $x \ensuremath{\in} F_{\ensuremath{\infty},S}$. Show that
\[
{f^{\rm FP}(x+h) \ensuremath{\ominus} f^{\rm FP}(x-h) \over  2h} = f'(x) + \ensuremath{\varepsilon}
\]
where the (absolute) error is bounded by
\[
|\ensuremath{\varepsilon}| \ensuremath{\leq} {|f'(x)| \over 2} \ensuremath{\epsilon}_{\rm m} + {M \over 3} h^2 + {2 c \ensuremath{\epsilon}_{\rm m} \over h}.
\]
\textbf{Problem 7(b)} Use the previous result to deduce, heuristically, an $\ensuremath{\alpha}$ such that choosing $h = C \ensuremath{\epsilon}_{\rm m}^\ensuremath{\alpha}$ will result in, roughly, optimal accuracy.

\rule{\textwidth}{1pt}
We can also bound the errors in expressions involving many floating point numbers, a property that is necessary for bounding the error in more complicated algorithms.  We first deduce a convenient function $E_{n,\ensuremath{\epsilon}}$ which will be used in the resulting error bounds:

\rule{\textwidth}{1pt}
\textbf{Problem 8(a)} Suppose $|\ensuremath{\epsilon}_k| \ensuremath{\leq} \ensuremath{\epsilon}$ and $n \ensuremath{\epsilon} < 1$. Show that $\ensuremath{\prod}_{k=1}^n (1+\ensuremath{\epsilon}_k) = 1+\ensuremath{\theta}_n$ for some constant $\ensuremath{\theta}_n$ satisfying
\[
|\ensuremath{\theta}_n| \ensuremath{\leq} \underbrace{n \ensuremath{\epsilon} \over 1-n\ensuremath{\epsilon}}_{E_{n,\ensuremath{\epsilon}}}.
\]
\rule{\textwidth}{1pt}
We finally are in a place to bound products and additions of $n$ floating point numbers. This lays the ground-work for understanding errors in simple algorithms such as in  linear algebra.

\rule{\textwidth}{1pt}
\textbf{Problem 8(b)} Show if $x_1,\ensuremath{\ldots},x_n \ensuremath{\in} F_{\ensuremath{\infty},S}$ then
\[
x_1 \ensuremath{\otimes} \ensuremath{\cdots} \ensuremath{\otimes} x_n = x_1 \ensuremath{\cdots} x_n (1 + \ensuremath{\theta}_{n-1})
\]
where $|\ensuremath{\theta}_n| \ensuremath{\leq} E_{n,\ensuremath{\epsilon}_{\rm m}/2}$, assuming $n \ensuremath{\epsilon}_{\rm m} < 2$.

\textbf{Problem 8(c)} Show if $x_1,\ensuremath{\ldots},x_n \ensuremath{\in} F_{\ensuremath{\infty},S}$ then
\[
x_1 \ensuremath{\oplus} \ensuremath{\cdots} \ensuremath{\oplus} x_n = x_1 +  \ensuremath{\cdots} + x_n + \ensuremath{\sigma}_n
\]
where, for $M = \ensuremath{\Sigma}_{k=1}^n |x_k|$, $|\ensuremath{\sigma}_n| \ensuremath{\leq} M E_{n-1,\ensuremath{\epsilon}_{\rm m}/2},$ assuming $n \ensuremath{\epsilon}_{\rm m} < 2$.

\rule{\textwidth}{1pt}


\end{document}