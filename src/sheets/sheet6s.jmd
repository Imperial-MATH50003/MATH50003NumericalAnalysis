**Numerical Analysis MATH50003 (2023–24) Problem Sheet 6**

**Problem 1** By computing the Cholesky factorisation, determine
which of the following matrices are symmetric positive definite:
$$
\begin{bmatrix} 1 & -1  \\
-1 & 3
\end{bmatrix}, \begin{bmatrix} 1 & 2 & 2  \\
2 & 1 & 2\\
2 & 2 & 1
\end{bmatrix}, \begin{bmatrix} 3 & 2 & 1  \\
2 & 4 & 2\\
1 & 2 & 5
\end{bmatrix},
\begin{bmatrix} 4 & 2 & 2 & 1  \\
2 & 4 & 2 & 2\\
2 & 2 & 4 & 2 \\
1 & 2 & 2 & 4
\end{bmatrix}
$$

**SOLUTION**

A matrix is symmetric positive definite (SPD) if and only if it has a Cholesky factorisation, so the task here is really just to compute Cholesky factorisations (by hand). Since our goal is to tell if the Cholesky factorisations exist, we do not have to compute $L_k$'s. We only need to see if the factorisation process can continue to the end.

*Matrix 1*

$$A_0=\begin{bmatrix} 1 & -1  \\
-1 & 3
\end{bmatrix}$$
and     $A_1=3-\frac{(-1)×(-1)}{1}>0$, so Matrix 1 is SPD.

*Matrix 2*

$$A_0=\begin{bmatrix}
1 & 2 & 2 \\
2 & 1 & 2 \\
2 & 2 & 1
\end{bmatrix}$$
Then
$$
A_1=\begin{bmatrix}
1&2\\
2&1
\end{bmatrix}-\begin{bmatrix} 2 \\ 2 \end{bmatrix}\begin{bmatrix} 2 & 2 \end{bmatrix}=
\begin{bmatrix}
-3&-2\\
-2&-3
\end{bmatrix}
$$
and finally $A_1[1,1] ≤ 0$, so Matrix 2 is not SPD.

*Matrix 3*

$$A_0=\begin{bmatrix}
3 & 2 & 1 \\
2 & 4 & 2 \\
1 & 2 & 5
\end{bmatrix}$$
and then
$$
A_1=
\begin{bmatrix}
4&2\\
2&5
\end{bmatrix}-\frac{1}{3}\begin{bmatrix} 2 \\ 1 \end{bmatrix}\begin{bmatrix} 2 & 1 \end{bmatrix}=\frac{1}{3}
\begin{bmatrix}
8&4\\
4&14
\end{bmatrix}
$$
and finally $3A_2=14-\frac{4× 4}{8} = 12 >0$, so Matrix 3 is SPD.

*Matrix 4*

$$
A_0=\begin{bmatrix}
4 & 2 & 2 & 1 \\
2 & 4 & 2 & 2 \\
2 & 2 & 4 & 2 \\
1 & 2 & 2 & 4
\end{bmatrix}
$$
and then
$$
A_1=\begin{bmatrix}
4&2&2\\
2&4&2\\
2&2&4
\end{bmatrix}-\frac{1}{4}\begin{bmatrix} 2 \\ 2 \\ 1 \end{bmatrix}\begin{bmatrix} 2 & 2 & 1 \end{bmatrix}=\frac{1}{4}
\begin{bmatrix}
12&4&6\\
4&12&6\\
6&6&15
\end{bmatrix}
$$
Furthermore
$$
4A_2=\begin{bmatrix}
12&6\\
6&15
\end{bmatrix}-\frac{1}{12}\begin{bmatrix} 4 \\ 6 \end{bmatrix}\begin{bmatrix} 4 & 6 \end{bmatrix}=\frac{4}{3}
\begin{bmatrix}
8&3\\
3&9
\end{bmatrix}
$$
and finally $3A_3=9-\frac{3× 3}{8}>0$, so Matrix 4 is SPD.


**END**

**Problem 2** Show that a matrix $A ∈ ℝ^{n × n}$ is symmetric positive definite if and only if it has a _reverse_ Cholesky
factorisation of the form
$$
A = U U^⊤
$$
where $U$ is upper triangular with positive entries on the diagonal.

**SOLUTION**

Note $𝐱^⊤ U U^⊤ 𝐱 = \| U^⊤ 𝐱 \| > 0$ since $U$ is invertible.

For the other direction, we replicate the proof by induction for standard Cholesky,
beginning in the bottom right
instead of the top left. Again the basis case is trivial. Since all diagonal entries are positive we can write
$$
A = \begin{bmatrix} K & 𝐯\\
                    𝐯^⊤ & α \end{bmatrix} =
                    \underbrace{\begin{bmatrix} I & {𝐯 \over \sqrt{α}} \\
                                        & \sqrt{α}
                                        \end{bmatrix}}_{U_1}
                    \begin{bmatrix} K - {𝐯 𝐯^⊤ \over α}  & \\
                     & 1 \end{bmatrix}
                     \underbrace{\begin{bmatrix} I \\
                      {𝐯^⊤ \over \sqrt{α}} & \sqrt{α}
                                        \end{bmatrix}}_{U_1^⊤}
$$
By assumption $K - {𝐯 𝐯^⊤ \over α} = \Ut\Ut^⊤$ hence we have
$$
A = \underbrace{U_1 \begin{bmatrix} \Ut \\ & 1 \end{bmatrix}}_U  \underbrace{\begin{bmatrix} \Ut^\top \\ & 1 \end{bmatrix} U_1^\top}_{U^\top}
$$


**END**


**Problem 3(a)** Use the Cholesky factorisation to prove that the following $n × n$ matrix is symmetric positive definite
for any $n$:
$$
Δ_n := \begin{bmatrix}
2 & -1 \\
-1 & 2 & -1 \\
& -1 & 2 & ⋱ \\
&& ⋱ & ⋱ & -1 \\
&&& -1 & 2
\end{bmatrix}
$$
Hint: consider a matrix $K_n^{(α)}$ that equals $Δ_n$ apart from the top left entry which is $α > 1$ and use a proof by induction.


**SOLUTION**

Consider the first step of the Cholesky factorisation:
$$
Δ_n = \begin{bmatrix} 2 & -𝐞_1^⊤ \\
                    -𝐞_1 & Δ_{n-1} \end{bmatrix} =
                    \underbrace{\begin{bmatrix} \sqrt{2} \\
                                    {-𝐞_1 \over \sqrt{2}} & I
                                        \end{bmatrix}}_{L_1}
                    \begin{bmatrix}1 \\ & Δ_{n-1} - {𝐞_1 𝐞_1^⊤ \over 2} \end{bmatrix}
                    \underbrace{\begin{bmatrix} \sqrt{2} & {-𝐞_1^⊤ \over \sqrt{2}} \\
                                                            & I
                                        \end{bmatrix}}_{L_1^⊤}
$$
The bottom right is merely $Δ_{n-1}$ but with a different $(1,1)$ entry! This hints at a strategy
of proving by induction.

Assuming $α > 1$ write
$$
K_n^{(α)} := \begin{bmatrix}
α & -1 \\
-1 & 2 & -1 \\
& -1 & 2 & ⋱ \\
&& ⋱ & ⋱ & -1 \\
&&& -1 & 2
\end{bmatrix} =
                    \begin{bmatrix} \sqrt{α} \\
                                    {-𝐞_1 \over \sqrt{α}} & I
                                        \end{bmatrix}
                    \begin{bmatrix}1 \\ & K_{n-1}^{(2 - 1/α)} \end{bmatrix}
                    \begin{bmatrix} \sqrt{α} & {-𝐞_1^⊤ \over \sqrt{α}} \\
                                                            & I
                                        \end{bmatrix}
$$
Note if $n = 1$ this is trivially SPD. Hence assume $K_{n-1}^{(α)}$ is SPD for all $α > 1$.
If $α > 1$ then $2 - 1/α > 1$. Hence by induction and the fact that $Δ_n = K_n^{(2)}$
we conclude that $Δ_n$ has a Cholesky factorisation and hence is symmetric positive definite.

**END**

**Problem 3(b)**
Deduce its Cholesky factorisations: $Δ_n = L_n L_n^⊤$ where
$L_n$ is lower triangular.

**SOLUTION**

We can  write down the factors explicitly: define $α_1 := 2$ and
$$
α_{k+1} = 2- 1/α_k.
$$
Let's try out the first few:
$$
α_1 = 2, α_2 = 3/2, α_3 = 4/3, α_4 = 5/4, …
$$
The pattern is clear and one can show by induction that $α_k = (k+1)/k$. Thus we have the Cholesky factorisation
$$
\meeq{
Δ _n = \underbrace{\begin{bmatrix}
\sqrt{2} \\
-1/\sqrt{2} & \sqrt{3/2} \\
& -\sqrt{2/3} & \sqrt{4/3} \\
    && ⋱ & ⋱ \\
    &&& -\sqrt{(n-1)/n} & \sqrt{(n+1)/n}
    \end{bmatrix}}_{L_n}  \\
    & \qquad ×     \underbrace{\begin{bmatrix}
\sqrt{2} & -1/\sqrt{2} \\
 & \sqrt{3/2} & -\sqrt{2/3} \\
    && ⋱ & ⋱ \\
    &&& \sqrt{n/(n-1)} & -\sqrt{(n-1)/n} \\
    &&&& \sqrt{(n+1)/n}
    \end{bmatrix}}_{L_n^⊤}
}
$$



**END**


**Problem 4** Use Lagrange interpolation to
interpolate the function $\cos x$ by a polynomial at the points
$[0,2,3,4]$ and evaluate at $x = 1$.

**SOLUTION**

- $ℓ_1(x)=\frac{(x-2)(x-3)(x-4)}{(0-2)(0-3)(0-4)}=-\frac{1}{24}(x-2)(x-3)(x-4)$
- $ℓ_2(x)=\frac{(x-0)(x-3)(x-4)}{(2-0)(2-3)(2-4)}=\frac{1}{4}x(x-3)(x-4)$
- $ℓ_3(x)=\frac{(x-0)(x-2)(x-4)}{(3-0)(3-2)(3-4)}=-\frac{1}{3}x(x-2)(x-4)$
- $ℓ_4(x)=\frac{(x-0)(x-2)(x-3)}{(4-0)(4-2)(4-3)}=\frac{1}{8}x(x-2)(x-3)$
So that $p(x)=\cos(0)ℓ_1(x)+\cos(2)ℓ_2(x)+\cos(3)ℓ_3(x)+\cos(4)ℓ_4(x)$. Note that $ℓ_0(1)=1/4$, $ℓ_2(1)=3/2$, $ℓ_3(1)=-1$, $ℓ_4(1)=1/4$, so $p(1)=1/4\cos(0)+3/2\cos(2)-\cos(3)+1/4\cos(4)$.


**END**

**Problem 5** Compute the LU factorisation of the following transposed Vandermonde matrices:
$$
\begin{bmatrix}
1 & 1 \\
x & y
\end{bmatrix},
\begin{bmatrix}
1 & 1 & 1 \\
x & y & z \\
x^2 & y^2 & z^2
\end{bmatrix},
\begin{bmatrix}
1 & 1 & 1 & 1 \\
x & y & z & t \\
x^2 & y^2 & z^2 & t^2 \\
x^3 & y^3 & z^3 & t^3
\end{bmatrix}
$$
Can you spot a pattern? Test your conjecture with a $5 × 5$ Vandermonde matrix.

**SOLUTION**
(1)
$$
\begin{bmatrix}
1 & 1 \\
x & y
\end{bmatrix} =  \begin{bmatrix}
1 &  \\
x & 1
\end{bmatrix} \begin{bmatrix}
1 & 1 \\
 & y-x
\end{bmatrix}
$$

(2)
$$
V := \begin{bmatrix}
1 & 1 & 1 \\
x & y & z \\
x^2 & y^2 & z^2
\end{bmatrix} =  \begin{bmatrix}
1 &  \\
x & 1 \\
x^2 && 1
\end{bmatrix} \begin{bmatrix}
1 & 1 & 1\\
 & y-x & z-x \\
 & y^2-x^2 & z^2 - x^2
\end{bmatrix}
$$
We then have
$$
\begin{bmatrix}
 y-x & z-x \\
 y^2-x^2 & z^2 - x^2
\end{bmatrix} = \begin{bmatrix}
 1 &  \\
 y+x & 1
\end{bmatrix} \begin{bmatrix}
y-x & z-x \\
& (z-y)(z-x)
\end{bmatrix}
$$
since $z^2 - x^2 - (z-x) (y+x) = z^2 + xy  - zy = (z-y)(z-x)$. Thus we have
$$
V = \begin{bmatrix}
1 &  \\
x & 1 \\
x^2 & x+y& 1
\end{bmatrix}  \begin{bmatrix}
1 & 1 & 1\\
 & y-x & z-x \\
 &  &  (z-y)(z-x)
\end{bmatrix}
$$

(3)
$$
V := \begin{bmatrix}
1 & 1 & 1 & 1 \\
x & y & z & t \\
x^2 & y^2 & z^2 & t^2 \\
x^3 & y^3 & z^3 & t^3
\end{bmatrix} =
\begin{bmatrix}
1 &  \\
x & 1 \\
x^2 && 1 \\
x^3 &&& 1
\end{bmatrix} \begin{bmatrix}
1 & 1 & 1 & 1\\
 & y-x & z-x & t-x \\
 & y^2-x^2 & z^2 - x^2 & t^2 - x^2 \\
 & y^3-x^3 & z^3 - x^3 & t^3 - x^3
\end{bmatrix}
$$
We then have
$$
\meeq{
\begin{bmatrix}
y-x & z-x & t-x \\
y^2-x^2 & z^2 - x^2 & t^2 - x^2 \\
y^3-x^3 & z^3 - x^3 & t^3 - x^3
\end{bmatrix} = \begin{bmatrix}
1 &  &  \\
y + x & 1 &  \\
y^2 + xy + x^2 &  & 1
\end{bmatrix} \\
& \qquad × \begin{bmatrix}
y-x & z-x & t-x \\
 & (z-y)(z-x) & (t-y)(t-x) \\
 & (z-x)(z-y) (x+y+z) & (t-x)(t-y) (x+y+t)
\end{bmatrix}
}
$$
since
$$
z^3 - x^3 - (z-x) (y^2 + x y + x^2) = z^3 - z y^2 - x y z  - z x^2 + x y^2  + x^2 y
= (x-z)(y-z) (x+y+z).
$$
Finally we have
$$
\begin{align*}
&\begin{bmatrix}
 (z-y)(z-x) & (t-y)(t-x) \\
 (z-x)(z-y) (x+y+z) & (t-x)(t-y) (x+y+t)
\end{bmatrix}\\
&\qquad = \begin{bmatrix}
 1 & \\
 x+y+z & 1
\end{bmatrix}
 \begin{bmatrix}
 (z-y)(z-x) & (t-y)(t-x) \\
  & (t-x)(t-y) (t-z)
\end{bmatrix}
\end{align*}
$$
since
$$
(t-x)(t-y) (x+y+t) - (x+y+z) (t-y)(t-x) = (t-y)(t-x)(t-z).
$$
Putting everything together we have
$$
V = \begin{bmatrix}
1 &  \\
x & 1 \\
x^2 & x+y  & 1 \\
x^3 &y^2 + xy + x^2  & x+ y + z & 1
\end{bmatrix} \begin{bmatrix}
1 & 1 & 1 & 1\\
 & y-x & z-x & t-x \\
 &  & (z-y)(z-x) & (t-y)(t-x) \\
 &  &  & (t-y)(t-x)(t-z)
\end{bmatrix}
$$


We conjecture that $L[k,j]$ for $k > j$ contains a sum of all monomials of degree $k$ of $x_1,…,x_j$, and
$$
U[k,j] = ∏_{s = 1}^{k-1} (x_j-x_s)
$$
for $1 < k ≤ j$. We can confirm that
$$
\begin{align*}
&\begin{bmatrix}
1 & 1 & 1 & 1 & 1 \\
x & y & z & t & s\\
x^2 & y^2 & z^2 & t^2 & s^2 \\
x^3 & y^3 & z^3 & t^3 & s^3 \\
x^4 & y^4 & z^4 & t^4 & s^4
\end{bmatrix} \\
&\qquad =
\begin{bmatrix}
1 &  \\
x & 1 \\
x^2 & x+y  & 1 \\
x^3 &y^2 + xy + x^2  & x+ y + z & 1 \\
x^4 & x^3 + x^2 y + x y^2 + y^3 & x^2 + y^2 + z^2 + xy + xz + yz  & x + y + z + t & 1
\end{bmatrix} \\
&\qquad ×
\begin{bmatrix}
1 & 1 & 1 & 1 & 1\\
 & y-x & z-x & t-x & s-x  \\
 &  & (z-y)(z-x) & (t-y)(t-x) & (s-x) (s-y) \\
 &  &  & (t-y)(t-x)(t-z) &   (s-y)(s-x)(s-z)  \\
 &  &  &  &   (s-y)(s-x)(s-z)(s-t)
\end{bmatrix}
\end{align*}
$$
Multiplying it out we confirm that our conjecture is correct in this case.

**END**